# GÃ¼n 29: TÉ™limin SonlandÄ±rÄ±lmasÄ± vÉ™ Modelin HazÄ±rlanmasÄ± ğŸ

## 29.1. TÉ™limin SonlandÄ±rÄ±lmasÄ± (Early Stopping)

LLM tÉ™limi Ã¼Ã§Ã¼n optimal sonlandÄ±rma nÃ¶qtÉ™si, modelin **É™n yaxÅŸÄ± Ã¼mumilÉ™ÅŸdirmÉ™ qabiliyyÉ™tinÉ™** malik olduÄŸu nÃ¶qtÉ™dir. Bu, adÉ™tÉ™n **Validasiya Loss-unun minimuma Ã§atdÄ±ÄŸÄ±** nÃ¶qtÉ™dir.

**MÉ™ntiq:** TÉ™lim Loss-u azalmaÄŸa davam etsÉ™ dÉ™, Validasiya Loss-u artmaÄŸa baÅŸlayÄ±rsa (Overfitting), tÉ™limi dÉ™rhal dayandÄ±rmaq lazÄ±mdÄ±r. Bu texnika **Early Stopping (ErkÉ™n DayandÄ±rma)** adlanÄ±r.

**ErkÉ™n DayandÄ±rma KriteriyasÄ±:**

1.  Validasiya Loss-u ardÄ±cÄ±l olaraq `Patience` (mÉ™sÉ™lÉ™n, 3) epoxa É™rzindÉ™ yaxÅŸÄ±laÅŸmÄ±rsa.
2.  TÉ™lim É™n yaxÅŸÄ± Validasiya Loss-u olan Checkpoint-dÉ™ dayandÄ±rÄ±lÄ±r.

## 29.2. Modelin HazÄ±rlanmasÄ± (Inference Export)

TÉ™lim baÅŸa Ã§atdÄ±qdan sonra, modelin Ã§É™kilÉ™ri **proqnozlaÅŸdÄ±rma (Inference)** Ã¼Ã§Ã¼n optimallaÅŸdÄ±rÄ±lmÄ±ÅŸ formata Ã§evrilmÉ™lidir.

**TÉ™lim VÉ™ziyyÉ™tindÉ™n FÉ™rqlÉ™r:**

*   **OptimallaÅŸdÄ±rÄ±cÄ±:** TÉ™lim Ã¼Ã§Ã¼n lazÄ±m olan optimallaÅŸdÄ±rÄ±cÄ± vÉ™ziyyÉ™ti (mÉ™sÉ™lÉ™n, AdamW-nin momentlÉ™ri) silinir.
*   **Model Rejimi:** Model `model.eval()` rejiminÉ™ keÃ§irilir.

**Praktika: Final Modelin SaxlanmasÄ±**

```python
import torch
import os
# GPTModel sinfini import edin

# 1. Æn yaxÅŸÄ± Checkpoint-i yÃ¼klÉ™mÉ™k
CHECKPOINT_DIR = "checkpoints/best_model"
if not os.path.exists(CHECKPOINT_DIR):
    print("XÉ™ta: Æn yaxÅŸÄ± Checkpoint tapÄ±lmadÄ±.")
    exit()

# 2. Modelin vÉ™ziyyÉ™tini yÃ¼klÉ™mÉ™k (accelerate-dÉ™n)
# accelerate load_state funksiyasÄ± modelin Ã§É™kilÉ™rini yÃ¼klÉ™yir.
model = GPTModel(vocab_size=32000, block_size=256, n_layer=12, n_head=12, n_embd=768)
# Bu hissÉ™ni accelerate olmadan icra etmÉ™k Ã¼Ã§Ã¼n:
# model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'pytorch_model.bin')))

# 3. Modeli proqnozlaÅŸdÄ±rma rejiminÉ™ keÃ§irmÉ™k
model.eval()

# 4. YalnÄ±z modelin Ã§É™kilÉ™rini saxlamaq (É™n yÃ¼ngÃ¼l format)
torch.save(model.state_dict(), 'az_llm_100m_final.pt')
print("Final model Ã§É™kilÉ™ri 'az_llm_100m_final.pt' faylÄ±na yazÄ±ldÄ±.")
```

## 29.3. Modelin Test EdilmÉ™si (Generasiya)

Modelin proqnozlaÅŸdÄ±rma rejimindÉ™ dÃ¼zgÃ¼n iÅŸlÉ™diyini yoxlamaq Ã¼Ã§Ã¼n **Generasiya (MÉ™tn Yaratma)** testi aparÄ±lÄ±r.

**MÉ™ntiq:** Generasiya zamanÄ± modelin Ã§É™kilÉ™ri dÉ™yiÅŸmir. Model yalnÄ±z verilmiÅŸ giriÅŸ ardÄ±cÄ±llÄ±ÄŸÄ±na É™sasÉ™n nÃ¶vbÉ™ti tokenin ehtimalÄ±nÄ± hesablayÄ±r.

**Generasiya AddÄ±mlarÄ±:**

1.  GiriÅŸ mÉ™tni tokenizasiya edilir.
2.  Token ID-lÉ™ri modelÉ™ verilir.
3.  Model nÃ¶vbÉ™ti tokenin ehtimalÄ±nÄ± (Logits) qaytarÄ±r.
4.  Bu ehtimallardan **Sampling** (GÃ¼n 20-dÉ™ Ã¶yrÉ™nilÉ™n) vasitÉ™silÉ™ bir token seÃ§ilir.
5.  SeÃ§ilmiÅŸ token giriÅŸ ardÄ±cÄ±llÄ±ÄŸÄ±na É™lavÉ™ edilir vÉ™ proses tÉ™krarlanÄ±r.

**Qeyd:** Bu mÉ™rhÉ™lÉ™dÉ™ modelin Ã§É™kilÉ™ri `az_llm_100m_final.pt` faylÄ±nda saxlanÄ±lÄ±r. Bu fayl nÃ¶vbÉ™ti mÉ™rhÉ™lÉ™dÉ™ **Hugging Face** formatÄ±na Ã§evrilÉ™cÉ™k.
