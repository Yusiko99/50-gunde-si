# GÃ¼n 29: TÉ™limin SonlandÄ±rÄ±lmasÄ± vÉ™ Modelin HazÄ±rlanmasÄ± ğŸ

## 29.1. TÉ™limi NÉ™ Vaxt SonlandÄ±rmalÄ±?

LLM tÉ™limi hÉ™ftÉ™lÉ™r, hÉ™tta aylar Ã§É™kÉ™ bilÉ™r. Lakin bizim 100M parametrli modelimiz Ã¼Ã§Ã¼n tÉ™limi sonlandÄ±rmaq qÉ™rarÄ± aÅŸaÄŸÄ±dakÄ± iki É™sas amilÉ™ É™saslanmalÄ±dÄ±r:

1.  **Validasiya Loss-unun DÉ™yiÅŸmÉ™si:** ÆgÉ™r Validasiya Loss-u ardÄ±cÄ±l olaraq bir neÃ§É™ epoxa É™rzindÉ™ azalmaÄŸÄ± dayandÄ±rÄ±rsa vÉ™ ya artmaÄŸa baÅŸlayÄ±rsa (Overfitting), tÉ™limi dayandÄ±rmaq lazÄ±mdÄ±r. Bu texnika **Early Stopping (ErkÉ™n DayandÄ±rma)** adlanÄ±r.
2.  **MÉ™tn GenerasiyasÄ±nÄ±n KeyfiyyÉ™ti:** Modelin yaratdÄ±ÄŸÄ± mÉ™tnlÉ™ri yoxlayÄ±n. ÆgÉ™r mÉ™tnlÉ™r axÄ±cÄ±, mÉ™ntiqli vÉ™ AzÉ™rbaycan dilinin qrammatikasÄ±na uyÄŸundursa, bu, modelin kifayÉ™t qÉ™dÉ™r Ã¶yrÉ™ndiyini gÃ¶stÉ™rir.

**UnutmayÄ±n:** TÉ™limi hÉ™miÅŸÉ™ É™n yaxÅŸÄ± **Validasiya Loss-u** olan Checkpoint-dÉ™ dayandÄ±rÄ±n.

## 29.2. Modelin HazÄ±rlanmasÄ± (Final Model Export)

TÉ™lim baÅŸa Ã§atdÄ±qdan sonra, biz modelin Ã§É™kilÉ™rini **tÉ™kcÉ™ proqnozlaÅŸdÄ±rma (inference)** Ã¼Ã§Ã¼n istifadÉ™ edilÉ™ bilÉ™cÉ™k formata Ã§evirmÉ™liyik.

**TÉ™limdÉ™n FÉ™rqli Olaraq:**

*   **OptimallaÅŸdÄ±rÄ±cÄ± (Optimizer):** ArtÄ±q lazÄ±m deyil.
*   **TÉ™lim ParametrlÉ™ri:** ArtÄ±q lazÄ±m deyil.
*   **Modelin Ã–zÃ¼:** YalnÄ±z modelin arxitekturasÄ± vÉ™ Ã¶yrÉ™nilmiÅŸ Ã§É™kilÉ™ri lazÄ±mdÄ±r.

**Final Modelin SaxlanmasÄ±:**

```python
# 1. Æn yaxÅŸÄ± Checkpoint-i yÃ¼klÉ™mÉ™k
checkpoint = torch.load('best_model_weights.pt')

# 2. Yeni bir model obyekti yaratmaq
final_model = GPTModel()

# 3. Ã‡É™kilÉ™ri yÃ¼klÉ™mÉ™k
final_model.load_state_dict(checkpoint['model_state_dict'])

# 4. Modeli CPU-ya kÃ¶Ã§Ã¼rmÉ™k (ÆgÉ™r GPU-da idisÉ™)
final_model.to('cpu')

# 5. Modeli proqnozlaÅŸdÄ±rma rejiminÉ™ keÃ§irmÉ™k
final_model.eval()

# 6. YalnÄ±z modelin Ã§É™kilÉ™rini saxlamaq (daha kiÃ§ik fayl)
torch.save(final_model.state_dict(), 'az_llm_100m_final.pt')
print("Final model Ã§É™kilÉ™ri 'az_llm_100m_final.pt' faylÄ±na yazÄ±ldÄ±.")
```

## 29.3. Modelin Test EdilmÉ™si (Generation)

Modeli yadda saxlamazdan É™vvÉ™l, onun mÉ™tn yaratma qabiliyyÉ™tini yoxlamalÄ±yÄ±q.

**`generate.py`**

```python
import torch
# GPTModel vÉ™ Tokenizer-i import edin

def generate_text(model, tokenizer, start_text, max_new_tokens=100):
    """Modelin mÉ™tn yaratma funksiyasÄ±."""
    
    # 1. GiriÅŸ mÉ™tnini token ID-lÉ™rinÉ™ Ã§evirmÉ™k
    encoded = tokenizer.encode(start_text)
    idx = torch.tensor(encoded.ids, dtype=torch.long).unsqueeze(0) # (1, T)
    
    # 2. MÉ™tn yaratmaq
    # Modelin Ã¶zÃ¼ndÉ™ki generate funksiyasÄ±nÄ± istifadÉ™ edirik
    # Bu funksiya hÉ™r dÉ™fÉ™ bir token proqnozlaÅŸdÄ±rÄ±r vÉ™ onu giriÅŸÉ™ É™lavÉ™ edir.
    generated_ids = model.generate(idx, max_new_tokens=max_new_tokens)
    
    # 3. Token ID-lÉ™rini mÉ™tnÉ™ Ã§evirmÉ™k
    generated_text = tokenizer.decode(generated_ids[0].tolist())
    
    return generated_text

# ... (Modeli yÃ¼klÉ™mÉ™k vÉ™ generate funksiyasÄ±nÄ± Ã§aÄŸÄ±rmaq) ...
```

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** TÉ™limi dayandÄ±rmaq Ã¼Ã§Ã¼n É™n yaxÅŸÄ± Validasiya Loss-u olan Checkpoint-i seÃ§in. Modelin Ã§É™kilÉ™rini `az_llm_100m_final.pt` faylÄ±na yadda saxlayÄ±n.
