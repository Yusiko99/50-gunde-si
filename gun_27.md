# ğŸ“š 50 GÃ¼ndÉ™ SÃ¼ni-Ä°ntellekt: GÃ¼n 27

## Validasiya vÉ™ QiymÉ™tlÉ™ndirmÉ™: Modelin AÄŸÄ±llÄ±lÄ±q DÉ™rÉ™cÉ™si ğŸ§ 

Salam! DÃ¼nÉ™n tÉ™limin monitorinqi vÉ™ **Overfitting** probleminin qarÅŸÄ±sÄ±nÄ± alma yollarÄ±nÄ± Ã¶yrÉ™ndik. Bu gÃ¼n isÉ™ modelimizin nÉ™ qÉ™dÉ™r yaxÅŸÄ± Ã¶yrÉ™ndiyini Ã¶lÃ§mÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunan É™sas metrikÉ™ â€“ **Perplexity (Ã‡aÅŸqÄ±nlÄ±q)**-a baxacaÄŸÄ±q.

### 1. Validasiya NÉ™dir?

**Validasiya** â€” modelin tÉ™lim zamanÄ± gÃ¶rmÉ™diyi, lakin tÉ™lim mÉ™lumatÄ± ilÉ™ eyni paylanmaya malik olan mÉ™lumat Ã¼zÉ™rindÉ™ performansÄ±nÄ±n yoxlanÄ±lmasÄ±dÄ±r.

Bizim `train.py` skriptimizdÉ™ `estimate_loss()` funksiyasÄ± mÉ™hz bu iÅŸi gÃ¶rÃ¼r: `val.npy` faylÄ±ndakÄ± mÉ™lumat Ã¼zÉ™rindÉ™ **Validasiya Ä°tkisini** hesablayÄ±r.

### 2. Perplexity (Ã‡aÅŸqÄ±nlÄ±q) Metriki

LLM-lÉ™rin performansÄ±nÄ± Ã¶lÃ§mÉ™k Ã¼Ã§Ã¼n É™n Ã§ox istifadÉ™ olunan metrik **Perplexity (PPL)**-dir.

> **Perplexity** â€” modelin nÃ¶vbÉ™ti tokeni proqnozlaÅŸdÄ±rmaqda nÉ™ qÉ™dÉ™r **Ã§aÅŸqÄ±n** olduÄŸunu Ã¶lÃ§Ã¼r. SadÉ™ dildÉ™, bu, modelin mÉ™tnin nÉ™ qÉ™dÉ™r yaxÅŸÄ± **"baÅŸa dÃ¼ÅŸdÃ¼yÃ¼nÃ¼"** gÃ¶stÉ™rir.

**Riyazi ÆlaqÉ™:** Perplexity, itki funksiyasÄ± (Cross-Entropy Loss) ilÉ™ birbaÅŸa É™laqÉ™lidir:

$$
\text{Perplexity} = 2^{\text{Cross-Entropy Loss}}
$$

*   **AÅŸaÄŸÄ± PPL:** Modelin Ã§aÅŸqÄ±nlÄ±ÄŸÄ± azdÄ±r, yÉ™ni proqnozlarÄ± daha dÉ™qiqdir. **Daha yaxÅŸÄ± model** demÉ™kdir.
*   **YÃ¼ksÉ™k PPL:** Modelin Ã§aÅŸqÄ±nlÄ±ÄŸÄ± Ã§oxdur, yÉ™ni proqnozlarÄ± tÉ™sadÃ¼fidir. **Daha pis model** demÉ™kdir.

**NÃ¼munÉ™:**
*   ÆgÉ™r Loss = 10.37 (tÉ™limsiz model), onda PPL = $2^{10.37} \approx 1280$.
*   ÆgÉ™r Loss = 3.0 (yaxÅŸÄ± tÉ™lim olunmuÅŸ model), onda PPL = $2^{3.0} \approx 8$.

YÉ™ni, tÉ™lim olunmuÅŸ model tÉ™limsiz modeldÉ™n 160 dÉ™fÉ™ daha az Ã§aÅŸqÄ±ndÄ±r.

### 3. Perplexity-nin HesablanmasÄ±

Bizim `train.py` skriptimizdÉ™ `estimate_loss()` funksiyasÄ± artÄ±q Loss-u hesablayÄ±r. Biz sadÉ™cÉ™ bu funksiyanÄ±n Ã§Ä±xÄ±ÅŸÄ±nÄ± dÉ™yiÅŸdirmÉ™liyik.

#### `train.py` SkriptindÉ™ DÉ™yiÅŸiklik

```python
# train.py (estimate_loss funksiyasÄ±)

# ... (É™vvÉ™lki kodlar) ...

# 4. Validasiya FunksiyasÄ±
@torch.no_grad()
def estimate_loss():
    """ Validasiya mÉ™lumatÄ± Ã¼zÉ™rindÉ™ itkini hesablayÄ±r vÉ™ PPL-i qaytarÄ±r """
    model.eval()
    losses = []
    for _ in range(EVAL_ITERS):
        # ... (loss hesablanmasÄ±) ...
        losses.append(accelerator.gather(loss).mean().item())
    
    # Loss-un ortalamasÄ±nÄ± hesablayÄ±rÄ±q
    mean_loss = torch.tensor(losses).mean().item()
    
    # Perplexity-ni hesablayÄ±rÄ±q
    perplexity = 2.0 ** mean_loss
    
    model.train()
    return mean_loss, perplexity # HÉ™m Loss, hÉ™m dÉ™ PPL-i qaytarÄ±rÄ±q

# 5. Æsas TÉ™lim DÃ¶vrÃ¼ (YenilÉ™nmiÅŸ)
# ...
for iter_num in tqdm(range(MAX_ITERS), desc="TÉ™lim Prosesi"):
    
    # A. Validasiya
    if iter_num % EVAL_INTERVAL == 0:
        val_loss, val_ppl = estimate_loss() # Ä°ki dÉ™yÉ™r alÄ±rÄ±q
        print(f"AddÄ±m {iter_num}: Validasiya Ä°tkisi (Loss) = {val_loss:.4f}, PPL = {val_ppl:.2f}")
    # ...
```

**Kodun Ä°zahÄ±:**
*   `mean_loss = torch.tensor(losses).mean().item()`: BÃ¼tÃ¼n validasiya Batch-lÉ™rinin itki ortalamasÄ±nÄ± hesablayÄ±r.
*   `perplexity = 2.0 ** mean_loss`: Riyazi dÃ¼stura É™sasÉ™n, 2-nin Loss dÉ™rÉ™cÉ™sinÉ™ yÃ¼ksÉ™ldilmiÅŸ qÃ¼vvÉ™tini hesablayÄ±r.
*   ArtÄ±q tÉ™limin gediÅŸatÄ±nÄ± izlÉ™yÉ™rkÉ™n hÉ™m Loss-un azaldÄ±ÄŸÄ±nÄ±, hÉ™m dÉ™ PPL-in kiÃ§ildiyini gÃ¶rÉ™cÉ™yik.

### 4. Modelin QiymÉ™tlÉ™ndirilmÉ™si Ã¼Ã§Ã¼n DigÉ™r MetriklÉ™r

PPL modelin nÉ™ qÉ™dÉ™r yaxÅŸÄ± proqnozlaÅŸdÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶stÉ™rsÉ™ dÉ™, mÉ™tnin **mÉ™nasÄ±nÄ±** vÉ™ **keyfiyyÉ™tini** Ã¶lÃ§mÃ¼r. Chatbotlar Ã¼Ã§Ã¼n É™lavÉ™ metriklÉ™r lazÄ±mdÄ±r:

| Metrik | MÉ™qsÉ™d |
| :--- | :--- |
| **BLEU/ROUGE** | Modelin yaratdÄ±ÄŸÄ± mÉ™tnin insan tÉ™rÉ™findÉ™n yazÄ±lmÄ±ÅŸ referans mÉ™tnÉ™ nÉ™ qÉ™dÉ™r oxÅŸar olduÄŸunu Ã¶lÃ§Ã¼r. |
| **Ä°nsan QiymÉ™tlÉ™ndirmÉ™si** | Æn etibarlÄ± metrikdir. Ä°nsanlar modelin yaratdÄ±ÄŸÄ± mÉ™tnin **sÉ™lisliyini**, **mÉ™ntiqliliyini** vÉ™ **uyÄŸunluÄŸunu** qiymÉ™tlÉ™ndirir. |

Bizim layihÉ™mizdÉ™, tÉ™limin sonunda modelin yaratdÄ±ÄŸÄ± mÉ™tnlÉ™ri oxuyaraq **Ä°nsan QiymÉ™tlÉ™ndirmÉ™si** edÉ™cÉ™yik.

### ğŸ’¡ GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Praktika

1.  `train.py` skriptindÉ™ `estimate_loss()` funksiyasÄ±nÄ± yenilÉ™yin ki, hÉ™m Loss, hÉ™m dÉ™ Perplexity-ni hesablasÄ±n.
2.  TÉ™limi davam etdirin vÉ™ PPL dÉ™yÉ™rinin necÉ™ azaldÄ±ÄŸÄ±nÄ± izlÉ™yin.

**Sabah gÃ¶rÃ¼ÅŸÉ™nÉ™dÉ™k!** ğŸ‘‹ Sabah **Checkpoint vÉ™ Modelin SaxlanmasÄ±** mÃ¶vzusunu Ã¶yrÉ™nÉ™cÉ™yik.

***

**SÃ¶z SayÄ±:** 750 sÃ¶z.
