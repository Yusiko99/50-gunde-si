# GÃ¼n 27: Validasiya vÉ™ QiymÉ™tlÉ™ndirmÉ™ ğŸ”¬

## 27.1. Validasiya NÉ™dir?

**Validasiya (Validation)** tÉ™lim prosesinin ayrÄ±lmaz hissÉ™sidir. Bizim modelimiz tÉ™lim mÉ™lumatlarÄ± Ã¼zÉ™rindÉ™ Ã¶yrÉ™nir, lakin biz onun **gÃ¶rmÉ™diyi** mÉ™lumatlar Ã¼zÉ™rindÉ™ nÉ™ qÉ™dÉ™r yaxÅŸÄ± iÅŸlÉ™diyini bilmÉ™liyik. Bu mÉ™qsÉ™dlÉ™, GÃ¼n 12-dÉ™ mÉ™lumatÄ±mÄ±zÄ±n 10%-ni **Validasiya DÉ™sti** kimi ayÄ±rmÄ±ÅŸdÄ±q.

**ValidasiyanÄ±n Æsas MÉ™qsÉ™di:**

1.  **Overfitting-in QarÅŸÄ±sÄ±nÄ± Almaq:** Modelin É™zbÉ™rlÉ™mÉ™yib, hÉ™qiqÉ™tÉ™n Ã¶yrÉ™ndiyini yoxlamaq.
2.  **HiperparametrlÉ™rin SeÃ§imi:** Æn yaxÅŸÄ± Ã¶yrÉ™nmÉ™ sÃ¼rÉ™ti, Batch Size vÉ™ s. kimi hiperparametrlÉ™ri seÃ§mÉ™yÉ™ kÃ¶mÉ™k etmÉ™k.

## 27.2. Modelin QiymÉ™tlÉ™ndirilmÉ™si

TÉ™lim baÅŸa Ã§atdÄ±qdan sonra modelin performansÄ±nÄ± Ã¶lÃ§mÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunan É™sas metrikalar bunlardÄ±r:

### A. Perplexity (PPL)

GÃ¼n 26-da Ã¶yrÉ™ndiyimiz kimi, PPL dil modelinin nÉ™ qÉ™dÉ™r yaxÅŸÄ± proqnozlaÅŸdÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶stÉ™rir.

### B. MÉ™tn GenerasiyasÄ± (Text Generation)

LLM-in É™sas mÉ™qsÉ™di mÉ™tn yaratmaqdÄ±r. Buna gÃ¶rÉ™ dÉ™, modelin keyfiyyÉ™tini qiymÉ™tlÉ™ndirmÉ™yin É™n yaxÅŸÄ± yolu, onun yaratdÄ±ÄŸÄ± mÉ™tnlÉ™ri **insan gÃ¶zÃ¼ ilÉ™** oxumaqdÄ±r.

**QiymÉ™tlÉ™ndirmÉ™ KriteriyalarÄ±:**

1.  **AxÄ±cÄ±lÄ±q (Fluency):** MÉ™tn qrammatik cÉ™hÉ™tdÉ™n dÃ¼zgÃ¼ndÃ¼rmÃ¼?
2.  **MÉ™ntiqlilik (Coherence):** MÉ™tn mÃ¶vzu daxilindÉ™ mÉ™ntiqli vÉ™ ardÄ±cÄ±lmÄ±?
3.  **UyÄŸunluq (Relevance):** Modelin cavabÄ± verilÉ™n suala vÉ™ ya baÅŸlanÄŸÄ±c mÉ™tndÉ™ki kontekstÉ™ uyÄŸundurmu?

## 27.3. Praktika: Validasiya Loss-unun HesablanmasÄ±

GÃ¼n 26-da `estimate_loss` funksiyasÄ±nÄ± tÉ™qdim etdik. Bu funksiya validasiya dÉ™sti Ã¼zÉ™rindÉ™ modelin performansÄ±nÄ± Ã¶lÃ§Ã¼r.

**`estimate_loss` funksiyasÄ±nÄ±n É™sas addÄ±mlarÄ±:**

1.  **`model.eval()`:** Modeli qiymÉ™tlÉ™ndirmÉ™ rejiminÉ™ keÃ§irir. Bu rejimdÉ™ **Dropout** vÉ™ **Batch Normalization** (bizim modeldÉ™ yoxdur) kimi laylar deaktiv edilir.
2.  **`torch.no_grad()`:** QradiyentlÉ™rin hesablanmasÄ±nÄ± dayandÄ±rÄ±r. Bu, VRAM-a qÉ™naÉ™t edir vÉ™ hesablama sÃ¼rÉ™tini artÄ±rÄ±r.
3.  **Loss-un HesablanmasÄ±:** Validasiya dÉ™stinin bÃ¼tÃ¼n Batch-lÉ™ri Ã¼zÉ™rindÉ™ Loss hesablanÄ±r.
4.  **`model.train()`:** QiymÉ™tlÉ™ndirmÉ™ bitdikdÉ™n sonra model tÉ™lim rejiminÉ™ qaytarÄ±lÄ±r.

## 27.4. Modelin SaxlanmasÄ± (Checkpointing)

Validasiya Loss-u É™n aÅŸaÄŸÄ± olan modeli saxlamaq Ã§ox vacibdir.

**Æn YaxÅŸÄ± Modelin SaxlanmasÄ±:**

```python
# Tutaq ki, bu, É™n yaxÅŸÄ± validasiya loss-udur
best_val_loss = float('inf') 

# TÉ™lim dÃ¶vrÃ¼ daxilindÉ™, hÉ™r 1000 addÄ±mda:
if val_loss < best_val_loss:
    best_val_loss = val_loss
    
    # Modelin Ã§É™kilÉ™rini yadda saxlamaq
    torch.save(model.state_dict(), 'best_model_weights.pt')
    print("Yeni É™n yaxÅŸÄ± model Ã§É™kilÉ™ri yadda saxlanÄ±ldÄ±!")
```

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** `train_accelerate.py` skriptinizdÉ™ É™n yaxÅŸÄ± validasiya loss-una É™sasÉ™n model Ã§É™kilÉ™rini yadda saxlama mexanizmini tÉ™tbiq edin.
