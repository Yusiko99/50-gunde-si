# GÃ¼n 27: Validasiya vÉ™ QiymÉ™tlÉ™ndirmÉ™ (Overfitting-in QarÅŸÄ±sÄ±nÄ±n AlÄ±nmasÄ±) ğŸ›¡ï¸

## 27.1. ValidasiyanÄ±n MÉ™ntiqi ÆsasÄ±

**Validasiya (Validation)** prosesi, modelin tÉ™lim mÉ™lumatlarÄ± Ã¼zÉ™rindÉ™ deyil, **gÃ¶rmÉ™diyi** (Validasiya) mÉ™lumatlar Ã¼zÉ™rindÉ™ki performansÄ±nÄ± Ã¶lÃ§mÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunur.

**MÉ™ntiq:** TÉ™lim Loss-unun azalmasÄ± modelin Ã¶yrÉ™ndiyini gÃ¶stÉ™rir, lakin Validasiya Loss-unun azalmasÄ± modelin **Ã¼mumilÉ™ÅŸdirmÉ™ (generalization)** qabiliyyÉ™tini gÃ¶stÉ™rir.

| VÉ™ziyyÉ™t | TÉ™lim Loss-u | Validasiya Loss-u | NÉ™ticÉ™ |
| :--- | :--- | :--- | :--- |
| **Normal TÉ™lim** | AzalÄ±r | AzalÄ±r | Model hÉ™m Ã¶yrÉ™nir, hÉ™m dÉ™ Ã¼mumilÉ™ÅŸdirir. |
| **Overfitting** | AzalÄ±r | ArtÄ±r | Model tÉ™lim mÉ™lumatlarÄ±nÄ± **É™zbÉ™rlÉ™yir**, lakin yeni mÉ™lumatlarÄ± proqnozlaÅŸdÄ±ra bilmir. **TÉ™limi dayandÄ±rmaq lazÄ±mdÄ±r.** |
| **Underfitting** | YÃ¼ksÉ™k | YÃ¼ksÉ™k | Model kifayÉ™t qÉ™dÉ™r Ã¶yrÉ™nmÉ™yib. Daha uzun tÉ™lim vÉ™ ya daha bÃ¶yÃ¼k model tÉ™lÉ™b olunur. |

## 27.2. Praktika: Validasiya FunksiyasÄ±

Validasiya, tÉ™lim dÃ¶vrÃ¼ndÉ™n kÉ™narda, adÉ™tÉ™n hÉ™r epoxanÄ±n sonunda icra olunur.

**`train_accelerate.py` SkriptinÉ™ ÆlavÉ™:**

```python
@torch.no_grad() # Qradiyent hesablamasÄ±nÄ± sÃ¶ndÃ¼rmÉ™k
def validate(model, val_dataloader, accelerator):
    """Validasiya mÉ™lumatlarÄ± Ã¼zÉ™rindÉ™ modelin performansÄ±nÄ± Ã¶lÃ§Ã¼r."""
    model.eval() # Modeli proqnozlaÅŸdÄ±rma rejiminÉ™ keÃ§irmÉ™k
    total_loss = 0
    
    # Validasiya dataloader-i Ã¼zÉ™rindÉ™ iterasiya
    for batch in val_dataloader:
        X, Y = batch[0][:, :-1], batch[0][:, 1:]
        
        # Modelin proqnozlaÅŸdÄ±rÄ±lmasÄ±
        # Loss hesablamaq Ã¼Ã§Ã¼n modelin Ã§Ä±xÄ±ÅŸÄ±nÄ± istifadÉ™ edirik
        logits, loss = model(X, Y)
        
        # Loss-u toplamaq
        total_loss += loss.item()
        
    avg_loss = total_loss / len(val_dataloader)
    
    # Perplexity (PPL) hesablamaq
    ppl = torch.exp(torch.tensor(avg_loss)).item()
    
    model.train() # Modeli tÉ™lim rejiminÉ™ qaytarmaq
    
    return avg_loss, ppl

# ... (TÉ™lim dÃ¶vrÃ¼) ...

for epoch in range(NUM_EPOCHS):
    # ... (TÉ™lim addÄ±mlarÄ±) ...
    
    # HÉ™r epoxanÄ±n sonunda Validasiya
    val_loss, val_ppl = validate(model, val_dataloader, accelerator)
    
    accelerator.print(f"--- Epoch {epoch} Validasiya NÉ™ticÉ™lÉ™ri ---")
    accelerator.print(f"Validasiya Loss: {val_loss:.4f}")
    accelerator.print(f"Validasiya Perplexity (PPL): {val_ppl:.2f}")
    
    # TensorBoard-a loglamaq
    writer.add_scalar('Loss/Validation', val_loss, global_step)
    writer.add_scalar('Perplexity/Validation', val_ppl, global_step)
    
    # Checkpoint saxlamaq (GÃ¼n 28-dÉ™ Ã¶yrÉ™nilÉ™cÉ™k)
    # Æn yaxÅŸÄ± Validasiya Loss-u olan modeli saxlamaq lazÄ±mdÄ±r.
```

## 27.3. Kodun MÉ™ntiqi Ä°zahÄ±

| SÉ™tr | Kod | MÉ™ntiqi Æsas |
| :--- | :--- | :--- |
| **1** | `@torch.no_grad()` | **Kritik:** Validasiya zamanÄ± qradiyentlÉ™rin hesablanmasÄ±na ehtiyac yoxdur. Bu, hÉ™m hesablama sÃ¼rÉ™tini artÄ±rÄ±r, hÉ™m dÉ™ VRAM istifadÉ™sini azaldÄ±r. |
| **2** | `model.eval()` | **MÉ™ntiq:** Modeli **Evaluation (QiymÉ™tlÉ™ndirmÉ™)** rejiminÉ™ keÃ§irir. Bu, **Dropout** vÉ™ **Batch Normalization** kimi tÉ™limÉ™ xas olan mexanizmlÉ™ri sÃ¶ndÃ¼rÃ¼r. |
| **14** | `ppl = torch.exp(torch.tensor(avg_loss)).item()` | **Perplexity HesablanmasÄ±:** Loss-un eksponensial funksiyasÄ±dÄ±r. Bu, modelin dil Ã¼zÉ™rindÉ™ki qabiliyyÉ™tini daha asan baÅŸa dÃ¼ÅŸÃ¼lÉ™n bir Ã¶lÃ§Ã¼ ilÉ™ ifadÉ™ edir. |
| **16** | `model.train()` | Validasiya bitdikdÉ™n sonra modelin tÉ™lim rejiminÉ™ qaytarÄ±lmasÄ± vacibdir. |
| **24** | `val_loss, val_ppl = validate(model, val_dataloader, accelerator)` | **Overfitting-in AÅŸkarlanmasÄ±:** TÉ™lim Loss-u azalarkÉ™n Validasiya Loss-u artmaÄŸa baÅŸlasa, bu, Overfitting-in baÅŸlanÄŸÄ±cÄ±dÄ±r vÉ™ tÉ™lim dayandÄ±rÄ±lmalÄ±dÄ±r. |
