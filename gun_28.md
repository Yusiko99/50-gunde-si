# GÃ¼n 28: Checkpoint vÉ™ Modelin SaxlanmasÄ± ğŸ’¾

## 28.1. Checkpoint-in Funksional ÆhÉ™miyyÉ™ti

**Checkpoint (NÉ™zarÉ™t NÃ¶qtÉ™si)** tÉ™lim prosesinin mÃ¼É™yyÉ™n bir anÄ±nda modelin vÉ™ziyyÉ™tinin yadda saxlanmasÄ±dÄ±r.

**MÉ™ntiq:** LLM tÉ™limi uzunmÃ¼ddÉ™tli bir prosesdir. Checkpoint-lÉ™r tÉ™limin uÄŸursuzluq (elektrik kÉ™silmÉ™si, proqram xÉ™tasÄ±) sÉ™bÉ™bindÉ™n yarÄ±mÃ§Ä±q qalmasÄ± riskini sÄ±ÄŸortalayÄ±r vÉ™ modelin **É™n yaxÅŸÄ± performans gÃ¶stÉ™rdiyi** vÉ™ziyyÉ™ti saxlamaÄŸa imkan verir.

**Checkpoint-É™ Daxil EdilÉ™nlÉ™r:**

| MÉ™lumat | MÉ™qsÉ™d |
| :--- | :--- |
| **Modelin Ã‡É™kilÉ™ri** | Modelin Ã¶yrÉ™ndiyi bilik. |
| **OptimallaÅŸdÄ±rÄ±cÄ±nÄ±n VÉ™ziyyÉ™ti** | TÉ™limi davam etdirmÉ™k Ã¼Ã§Ã¼n lazÄ±m olan daxili dÉ™yiÅŸÉ™nlÉ™r (mÉ™sÉ™lÉ™n, AdamW-nin momentlÉ™ri). |
| **Cari Epoxa/AddÄ±m** | TÉ™limin hansÄ± nÃ¶qtÉ™dÉ™n davam etdirilÉ™cÉ™yini gÃ¶stÉ™rir. |
| **Æn YaxÅŸÄ± Validasiya Loss-u** | Modelin É™n yaxÅŸÄ± nÉ™ticÉ™ gÃ¶stÉ™rdiyi vÉ™ziyyÉ™ti mÃ¼É™yyÉ™nlÉ™ÅŸdirmÉ™k. |

## 28.2. `accelerate` ilÉ™ Checkpoint Mexanizmi

`accelerate` kitabxanasÄ± Checkpoint mexanizmini sadÉ™lÉ™ÅŸdirir vÉ™ bÃ¼tÃ¼n lazÄ±mi komponentlÉ™ri (model, optimizer, scheduler) avtomatik olaraq idarÉ™ edir.

**Saxlama MÉ™ntiqi:**

Æn yaxÅŸÄ± Checkpoint, adÉ™tÉ™n **É™n aÅŸaÄŸÄ± Validasiya Loss-una** malik olan Checkpoint-dir.

**`train_accelerate.py` SkriptinÉ™ ÆlavÉ™:**

```python
# ... (ÆvvÉ™lki kod) ...

# TÉ™lim dÃ¶vrÃ¼ndÉ™n É™vvÉ™l
best_val_loss = float('inf')
CHECKPOINT_DIR = "checkpoints"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# ... (TÉ™lim dÃ¶vrÃ¼) ...

for epoch in range(NUM_EPOCHS):
    # ... (TÉ™lim vÉ™ Validasiya) ...
    
    val_loss, val_ppl = validate(model, val_dataloader, accelerator)
    
    # 1. Æn YaxÅŸÄ± Checkpoint-i Yoxlamaq
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        
        # 2. Checkpoint-i Saxlamaq
        # accelerate avtomatik olaraq model, optimizer vÉ™ scheduler-i saxlayÄ±r.
        accelerator.save_state(os.path.join(CHECKPOINT_DIR, "best_model"))
        
        accelerator.print(f"Yeni É™n yaxÅŸÄ± Validasiya Loss-u ({best_val_loss:.4f}) tapÄ±ldÄ±. Checkpoint saxlandÄ±.")
        
    # HÉ™r epoxanÄ±n sonunda cari vÉ™ziyyÉ™ti saxlamaq (davam etdirmÉ™k Ã¼Ã§Ã¼n)
    accelerator.save_state(os.path.join(CHECKPOINT_DIR, f"epoch_{epoch}"))
```

## 28.3. Checkpoint-dÉ™n BÉ™rpa

TÉ™limi dayandÄ±rÄ±lmÄ±ÅŸ bir nÃ¶qtÉ™dÉ™n davam etdirmÉ™k Ã¼Ã§Ã¼n `accelerator.load_state()` funksiyasÄ±ndan istifadÉ™ olunur.

**BÉ™rpa MÉ™ntiqi:**

1.  **`accelerator.load_state(path)`** funksiyasÄ± modelin Ã§É™kilÉ™rini, optimallaÅŸdÄ±rÄ±cÄ±nÄ±n vÉ™ziyyÉ™tini vÉ™ scheduler-in vÉ™ziyyÉ™tini yÃ¼klÉ™yir.
2.  TÉ™lim dÃ¶vrÃ¼ yÃ¼klÉ™nmiÅŸ vÉ™ziyyÉ™tdÉ™n (mÉ™sÉ™lÉ™n, 5-ci epoxanÄ±n ortasÄ±ndan) davam edir.

**`train_accelerate.py` SkriptinÉ™ BÉ™rpa MÉ™ntiqi:**

```python
# ... (ÆvvÉ™lki kod) ...

# TÉ™lim dÃ¶vrÃ¼ndÉ™n É™vvÉ™l
CHECKPOINT_TO_LOAD = os.path.join(CHECKPOINT_DIR, "epoch_4") # MÉ™sÉ™lÉ™n, 4-cÃ¼ epoxadan davam etmÉ™k

if os.path.exists(CHECKPOINT_TO_LOAD):
    accelerator.load_state(CHECKPOINT_TO_LOAD)
    accelerator.print(f"Checkpoint '{CHECKPOINT_TO_LOAD}' uÄŸurla yÃ¼klÉ™ndi. TÉ™lim davam etdirilir.")
    # BaÅŸlanÄŸÄ±c epoxasÄ±nÄ± tÉ™yin etmÉ™k
    start_epoch = int(CHECKPOINT_TO_LOAD.split('_')[-1]) + 1
else:
    start_epoch = 0

# TÉ™lim dÃ¶vrÃ¼
for epoch in range(start_epoch, NUM_EPOCHS):
    # ... (TÉ™lim davam edir) ...
```

**MÉ™ntiq:** Bu mexanizm, xÃ¼susilÉ™ bulud xidmÉ™tlÉ™rindÉ™ vÉ™ ya mÉ™hdud resurslu kompÃ¼terlÉ™rdÉ™ (RTX 2050) tÉ™limin **etibarlÄ±lÄ±ÄŸÄ±nÄ±** vÉ™ **davamlÄ±lÄ±ÄŸÄ±nÄ±** tÉ™min edir.
