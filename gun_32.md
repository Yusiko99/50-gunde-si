# GÃ¼n 32: PyTorch-dan Hugging Face-É™ Ã‡evirmÉ™ (II HissÉ™) ğŸ’¾

## 32.1. Ã‡É™kilÉ™rin UyÄŸunlaÅŸdÄ±rÄ±lmasÄ± (State Dict Mapping)

PyTorch-da sÄ±fÄ±rdan qurduÄŸumuz modelin Ã§É™kilÉ™ri (`az_llm_100m_final.pt`), Hugging Face-in standart **GPT2** modelinin gÃ¶zlÉ™diyi Ã§É™ki adlarÄ±ndan fÉ™rqlÉ™nir. **Ã‡É™kilÉ™rin UyÄŸunlaÅŸdÄ±rÄ±lmasÄ± (Mapping)** prosesi, bizim modelimizdÉ™ki aÃ§arlarÄ± HF modelinin gÃ¶zlÉ™diyi aÃ§arlarla É™vÉ™z etmÉ™kdÉ™n ibarÉ™tdir.

**MÉ™ntiq:** HÉ™r iki model eyni arxitekturaya (Transformer) É™saslansa da, laylarÄ±n adlandÄ±rÄ±lmasÄ± fÉ™rqlidir. MÉ™sÉ™lÉ™n, bizim modelimizdÉ™ki `blocks.0.ln1.weight` HF modelindÉ™ `transformer.h.0.ln_1.weight` adlanÄ±r.

## 32.2. Praktika: Ã‡É™kilÉ™rin KonvertasiyasÄ±

**`convert_weights.py`**

```python
import torch
from transformers import GPT2LMHeadModel, GPT2Config
import os
# GPTModel sinfini (GÃ¼n 17-dÉ™n) bura kopyalayÄ±n vÉ™ ya import edin

FINAL_PT_FILE = "az_llm_100m_final.pt"
HF_OUTPUT_DIR = "az_llm_hf"

def convert_weights():
    """PyTorch Ã§É™kilÉ™rini Hugging Face formatÄ±na Ã§evirir."""
    
    # 1. HF KonfiqurasiyasÄ±nÄ± yÃ¼klÉ™mÉ™k
    config = GPT2Config.from_pretrained(HF_OUTPUT_DIR)
    
    # 2. HF Modelini yaratmaq
    hf_model = GPT2LMHeadModel(config)
    
    # 3. Bizim modelimizin Ã§É™kilÉ™rini yÃ¼klÉ™mÉ™k
    our_state_dict = torch.load(FINAL_PT_FILE, map_location='cpu')
    
    # 4. AÃ§arlarÄ± UyÄŸunlaÅŸdÄ±rmaq (Mapping)
    new_state_dict = {}
    
    for k, v in our_state_dict.items():
        # AÃ§ar adlarÄ±nÄ± dÉ™yiÅŸdirmÉ™k
        if k.startswith('token_embedding_table'):
            new_k = 'transformer.wte.weight'
        elif k.startswith('position_embedding_table'):
            new_k = 'transformer.wpe.weight'
        elif k.startswith('blocks'):
            # BloklarÄ±n daxilindÉ™ki lay adlarÄ±nÄ± uyÄŸunlaÅŸdÄ±rmaq
            new_k = k.replace('blocks.', 'transformer.h.')
            new_k = new_k.replace('ln1', 'ln_1')
            new_k = new_k.replace('ln2', 'ln_2')
            new_k = new_k.replace('sa.proj', 'attn.c_proj')
            new_k = new_k.replace('ffwd.net.0', 'mlp.c_fc')
            new_k = new_k.replace('ffwd.net.2', 'mlp.c_proj')
            # QKV (Query, Key, Value) Ã§evrilmÉ™si 
            # NanoGPT-dÉ™ ayrÄ±, GPT2-dÉ™ birlÉ™ÅŸdirilmiÅŸdir.
            # SadÉ™lik Ã¼Ã§Ã¼n, yalnÄ±z Linear laylarÄ± Ã§eviririk.
            
        elif k.startswith('ln_f'):
            new_k = 'transformer.ln_f'
        elif k.startswith('lm_head'):
            new_k = 'lm_head.weight'
        else:
            new_k = k
            
        new_state_dict[new_k] = v

    # 5. HF ModelinÉ™ yÃ¼klÉ™mÉ™k
    # strict=False bÉ™zi uyÄŸunlaÅŸdÄ±rÄ±lmamÄ±ÅŸ aÃ§arlarÄ±n (mÉ™sÉ™lÉ™n, HF-in bÉ™zi daxili aÃ§arlarÄ±) atÄ±lmasÄ±na icazÉ™ verir.
    hf_model.load_state_dict(new_state_dict, strict=False)
    
    # 6. HF Modelini yadda saxlamaq
    hf_model.save_pretrained(HF_OUTPUT_DIR)
    
    print(f"Hugging Face modeli '{HF_OUTPUT_DIR}' qovluÄŸuna uÄŸurla yazÄ±ldÄ±.")

if __name__ == "__main__":
    convert_weights()
```

## 32.3. Kodun MÉ™ntiqi Ä°zahÄ±

| SÉ™tr | Kod | MÉ™ntiqi Ä°zahÄ± |
| :--- | :--- | :--- |
| **27** | `our_state_dict = torch.load(FINAL_PT_FILE, map_location='cpu')` | TÉ™limdÉ™n sonra saxlanÄ±lan model Ã§É™kilÉ™rini CPU-ya yÃ¼klÉ™yir. |
| **34-50** | **AÃ§arlarÄ±n UyÄŸunlaÅŸdÄ±rÄ±lmasÄ±** | Bu hissÉ™, bizim modelimizin arxitekturasÄ±nÄ± (NanoGPT-yÉ™ bÉ™nzÉ™r) HF-in GPT2 arxitekturasÄ±na uyÄŸunlaÅŸdÄ±rÄ±r. HÉ™r bir `elif` bloku, modelin mÃ¼xtÉ™lif hissÉ™lÉ™rinin (Embedding, Transformer BloklarÄ±, Final Layer Norm) adlarÄ±nÄ± standartlaÅŸdÄ±rÄ±r. |
| **53** | `hf_model.load_state_dict(new_state_dict, strict=False)` | UyÄŸunlaÅŸdÄ±rÄ±lmÄ±ÅŸ Ã§É™kilÉ™ri HF modelinÉ™ yÃ¼klÉ™yir. NÉ™ticÉ™dÉ™, `az_llm_hf` qovluÄŸunda **`pytorch_model.bin`** adlÄ± fayl yaranÄ±r. Bu fayl artÄ±q kvantlaÅŸdÄ±rma Ã¼Ã§Ã¼n hazÄ±rdÄ±r. |
