# GÃ¼n 35: Ollama API ilÉ™ Ä°ÅŸlÉ™mÉ™k (Chatbotun QurulmasÄ±) ğŸ’¬

## 35.1. Modelin Ä°ÅŸÉ™ SalÄ±nmasÄ±

GÃ¼n 34-dÉ™ modelimizi Ollama-ya idxal etdik. Ä°ndi onu iÅŸÉ™ salmaÄŸÄ±n iki yolu var:

### A. Terminalda Ä°ÅŸÉ™ Salma (Chat)

Æn sadÉ™ yol terminalda birbaÅŸa modelimizlÉ™ sÃ¶hbÉ™t etmÉ™kdir:

```bash
ollama run az-llm-100m
```

Bu É™mr modeli iÅŸÉ™ salacaq vÉ™ sizÉ™ birbaÅŸa suallar vermÉ™yÉ™ imkan verÉ™cÉ™k.

### B. Ollama API ilÉ™ Ä°ÅŸlÉ™mÉ™k

ÆgÉ™r modelinizi bir proqrama (mÉ™sÉ™lÉ™n, Python-da chatbot interfeysinÉ™) inteqrasiya etmÉ™k istÉ™yirsinizsÉ™, **Ollama API**-dÉ™n istifadÉ™ etmÉ™lisiniz. Ollama API, modelinizÉ™ HTTP sorÄŸularÄ± vasitÉ™silÉ™ mÃ¼raciÉ™t etmÉ™yÉ™ imkan verÉ™n yerli bir serverdir.

## 35.2. Praktika: Python Chatbotu

Biz Python-un **`requests`** kitabxanasÄ±ndan istifadÉ™ edÉ™rÉ™k modelimizÉ™ sorÄŸu gÃ¶ndÉ™rÉ™n sadÉ™ bir chatbot skripti yazacaÄŸÄ±q.

**`chatbot.py`**

```python
import requests
import json

# Ollama API-nin standart Ã¼nvanÄ±
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "az-llm-100m"

def generate_response(prompt):
    """Ollama API-yÉ™ sorÄŸu gÃ¶ndÉ™rir vÉ™ cavabÄ± qaytarÄ±r."""
    
    # 1. SorÄŸu Ã¼Ã§Ã¼n JSON mÉ™lumatÄ±nÄ± hazÄ±rlamaq
    data = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False, # CavabÄ± axÄ±n ÅŸÉ™klindÉ™ deyil, tam ÅŸÉ™kildÉ™ almaq
        "options": {
            "temperature": 0.8,
            "num_predict": 100 # Maksimum 100 token yaratmaq
        }
    }
    
    # 2. API-yÉ™ POST sorÄŸusu gÃ¶ndÉ™rmÉ™k
    try:
        response = requests.post(OLLAMA_URL, json=data)
        response.raise_for_status() # XÉ™ta olarsa, xÉ™bÉ™rdarlÄ±q et
        
        # 3. CavabÄ± emal etmÉ™k
        result = response.json()
        
        # YalnÄ±z yaradÄ±lmÄ±ÅŸ mÉ™tni qaytarmaq
        return result.get("response", "Cavab alÄ±nmadÄ±.")
        
    except requests.exceptions.RequestException as e:
        return f"XÉ™ta: Ollama API-yÉ™ qoÅŸulmaq mÃ¼mkÃ¼n olmadÄ±. Ollama iÅŸlÉ™yirmi? ({e})"

def main_chatbot():
    """Æsas chatbot dÃ¶vrÃ¼."""
    print("--- AzÉ™rbaycan LLM Chatbotu (Ollama API) ---")
    print(f"Model: {MODEL_NAME}. Ã‡Ä±xmaq Ã¼Ã§Ã¼n 'Ã§Ä±x' yazÄ±n.")
    
    while True:
        user_input = input("Siz: ")
        if user_input.lower() == 'Ã§Ä±x':
            break
            
        if not user_input.strip():
            continue
            
        print("LLM: ZÉ™hmÉ™t olmasa gÃ¶zlÉ™yin...")
        response = generate_response(user_input)
        print(f"LLM: {response}")

if __name__ == "__main__":
    main_chatbot()
```

## 35.3. Kodun Ä°zahÄ±

| SÉ™tr | Kod | Ä°zahÄ± |
| :--- | :--- | :--- |
| **10** | `OLLAMA_URL = "http://localhost:11434/api/generate"` | Ollama-nÄ±n standart olaraq iÅŸlÉ™diyi yerli API Ã¼nvanÄ±. |
| **18** | `"stream": False` | MÉ™tnin hissÉ™-hissÉ™ deyil, tam ÅŸÉ™kildÉ™ gÉ™lmÉ™sini tÉ™min edir. |
| **20** | `"temperature": 0.8` | Modelin yaradÄ±cÄ±lÄ±q dÉ™rÉ™cÉ™si. YÃ¼ksÉ™k dÉ™yÉ™r daha yaradÄ±cÄ±, aÅŸaÄŸÄ± dÉ™yÉ™r daha dÉ™qiq cavab demÉ™kdir. |
| **20** | `"num_predict": 100` | Modelin maksimum neÃ§É™ token yaratacaÄŸÄ±nÄ± tÉ™yin edir. |
| **27** | `response = requests.post(OLLAMA_URL, json=data)` | HazÄ±rlanmÄ±ÅŸ JSON mÉ™lumatÄ±nÄ± API-yÉ™ gÃ¶ndÉ™rir. |
| **30** | `result = response.json()` | API-dÉ™n gÉ™lÉ™n JSON cavabÄ±nÄ± Python lÃ¼ÄŸÉ™tinÉ™ Ã§evirir. |
| **33** | `return result.get("response", ...)` | Cavabdan yalnÄ±z yaradÄ±lmÄ±ÅŸ mÉ™tn hissÉ™sini Ã§Ä±xarÄ±r. |

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** `chatbot.py` skriptini yaradÄ±n. Terminalda `ollama run az-llm-100m` É™mrini icra edin vÉ™ sonra ayrÄ± bir terminalda `python chatbot.py` É™mrini iÅŸÉ™ salÄ±n. ModelinizlÉ™ ilk sÃ¶hbÉ™tinizi edin!
