# ğŸ“š 50 GÃ¼ndÉ™ SÃ¼ni-Ä°ntellekt: GÃ¼n 35

## Ollama API ilÉ™ Ä°ÅŸlÉ™mÉ™k: Chatbotun Ä°nterfeysi ğŸ’»

Salam! DÃ¼nÉ™n modelimizi Ollama-da uÄŸurla yerlÉ™ÅŸdirdik vÉ™ terminaldan sÄ±naqdan keÃ§irdik. Bu gÃ¼n isÉ™ modelimizi Python kodumuzdan istifadÉ™ edÉ™ bilmÉ™k Ã¼Ã§Ã¼n **Ollama API** ilÉ™ iÅŸlÉ™mÉ™yi Ã¶yrÉ™nÉ™cÉ™yik.

### 1. Ollama API NÉ™dir?

Ollama, arxa planda iÅŸlÉ™yÉ™n bir serverdir vÉ™ **REST API** vasitÉ™silÉ™ mÃ¼raciÉ™tlÉ™ri qÉ™bul edir. Bu o demÉ™kdir ki, biz Python-dan adi HTTP sorÄŸularÄ± gÃ¶ndÉ™rÉ™rÉ™k modelimizlÉ™ danÄ±ÅŸa bilÉ™rik.

Biz bu prosesi asanlaÅŸdÄ±rmaq Ã¼Ã§Ã¼n **`ollama`** Python kitabxanasÄ±ndan istifadÉ™ edÉ™cÉ™yik.

### 2. `ollama` Python KitabxanasÄ±nÄ±n QuraÅŸdÄ±rÄ±lmasÄ±

```bash
pip install ollama
```

### 3. Python-dan ModelÉ™ MÃ¼raciÉ™t

AÅŸaÄŸÄ±dakÄ± kodu **`az_chatbot.py`** adlÄ± bir faylda yazaq.

```python
# az_chatbot.py
import ollama

# 1. Ollama Client-i Yaratmaq
# Ollama avtomatik olaraq yerli serverÉ™ (http://localhost:11434) qoÅŸulur
client = ollama.Client()

# 2. MÉ™tn GenerasiyasÄ± FunksiyasÄ±
def generate_response(prompt, model_name="az-nano-llm"):
    """ Ollama API vasitÉ™silÉ™ modeldÉ™n cavab alÄ±r """
    
    print(f"-> Sual: {prompt}")
    
    # API sorÄŸusunu gÃ¶ndÉ™ririk
    response = client.generate(
        model=model_name,
        prompt=prompt,
        # Ollama-nÄ±n default parametrlÉ™rini istifadÉ™ edirik
        options={
            "temperature": 0.8,
            "top_k": 50,
        }
    )
    
    # CavabÄ± Ã§Ä±xarÄ±rÄ±q
    return response['response']

# 3. Chatbot DÃ¶vrÃ¼
def run_chatbot():
    print("--- AzÉ™rbaycan Nano LLM Chatbotu BaÅŸladÄ± ---")
    print("Ã‡Ä±xmaq Ã¼Ã§Ã¼n 'Ã§Ä±x' yazÄ±n.")
    
    while True:
        user_input = input("Siz: ")
        
        if user_input.lower() in ['Ã§Ä±x', 'exit', 'quit']:
            print("Chatbot dayandÄ±rÄ±ldÄ±. SaÄŸ olun!")
            break
        
        # CavabÄ± alÄ±rÄ±q
        response = generate_response(user_input)
        
        # CavabÄ± ekrana yazdÄ±rÄ±rÄ±q
        print(f"Model: {response}")

if __name__ == "__main__":
    # Ollama serverinin iÅŸlÉ™diyindÉ™n É™min olun
    try:
        client.list() # Serverin iÅŸlÉ™diyini yoxlayÄ±r
        run_chatbot()
    except Exception as e:
        print("XÆTA: Ollama serveri iÅŸlÉ™mir.")
        print("ZÉ™hmÉ™t olmasa, Ollama proqramÄ±nÄ±n arxa planda iÅŸlÉ™diyindÉ™n É™min olun.")
```

### 4. Kodun Ä°zahÄ± (HÉ™r SÉ™trin DetallÄ± Ä°zahÄ±)

| SÉ™tr | Kod | Ä°zah |
| :--- | :--- | :--- |
| 5 | `import ollama` | Ollama Python kitabxanasÄ±nÄ± daxil edirik. |
| 8 | `client = ollama.Client()` | Ollama serveri ilÉ™ É™laqÉ™ qurmaq Ã¼Ã§Ã¼n bir client obyekti yaradÄ±rÄ±q. |
| 14 | `response = client.generate(...)` | **Æsas API Ã§aÄŸÄ±rÄ±ÅŸÄ±.** `generate` metodu modelÉ™ prompt gÃ¶ndÉ™rir vÉ™ cavab gÃ¶zlÉ™yir. |
| 15 | `model=model_name` | Ollama-da yaratdÄ±ÄŸÄ±mÄ±z modelin adÄ±nÄ± (`az-nano-llm`) gÃ¶stÉ™ririk. |
| 16 | `prompt=prompt` | Ä°stifadÉ™Ã§inin sualÄ±nÄ± modelÉ™ gÃ¶ndÉ™ririk. |
| 20 | `"temperature": 0.8` | GenerasiyanÄ±n yaradÄ±cÄ±lÄ±q sÉ™viyyÉ™sini tÉ™nzimlÉ™yir. |
| 24 | `return response['response']` | API-dÉ™n gÉ™lÉ™n JSON cavabÄ±ndan yalnÄ±z mÉ™tn hissÉ™sini Ã§Ä±xarÄ±rÄ±q. |
| 31 | `user_input = input("Siz: ")` | Ä°stifadÉ™Ã§idÉ™n sual qÉ™bul edir. |
| 43 | `client.list()` | Ollama serverinin iÅŸlÉ™diyini yoxlamaq Ã¼Ã§Ã¼n sadÉ™ bir API Ã§aÄŸÄ±rÄ±ÅŸÄ±dÄ±r. |

### 5. Ollama-da Chat Rejimi

Ollama hÉ™mÃ§inin **`chat`** adlÄ± xÃ¼susi bir API-yÉ™ malikdir ki, bu da sÃ¶hbÉ™t tarixÃ§É™sini (context) avtomatik idarÉ™ edir.

```python
# az_chatbot_chat.py (Chat API istifadÉ™si)
# ... (importlar vÉ™ client yaratmaq) ...

def chat_with_model(messages, model_name="az-nano-llm"):
    """ SÃ¶hbÉ™t tarixÃ§É™sini qoruyaraq cavab alÄ±r """
    
    response = client.chat(
        model=model_name,
        messages=messages,
    )
    
    # Yeni mesajÄ± tarixÃ§É™yÉ™ É™lavÉ™ edirik
    messages.append(response['message'])
    return response['message']['content']

# SÃ¶hbÉ™t tarixÃ§É™si
messages = []

# Sistem mesajÄ± (Modelfile-dakÄ± SYSTEM prompt-u É™vÉ™z edir)
messages.append({
    'role': 'system',
    'content': 'SÉ™n AzÉ™rbaycan dilindÉ™ danÄ±ÅŸan, faydalÄ± vÉ™ mÉ™lumatlandÄ±rÄ±cÄ± bir sÃ¼ni intellekt kÃ¶mÉ™kÃ§isisÉ™n.'
})

# Ä°lk sual
messages.append({
    'role': 'user',
    'content': 'AzÉ™rbaycanÄ±n É™n bÃ¶yÃ¼k Ã§ayÄ± hansÄ±dÄ±r?'
})

response = chat_with_model(messages)
print(f"Model: {response}")
```

### ğŸ’¡ GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Praktika

1.  `ollama` Python kitabxanasÄ±nÄ± quraÅŸdÄ±rÄ±n.
2.  `az_chatbot.py` faylÄ±nÄ± yaradÄ±n vÉ™ icra edin.
3.  ModelinizlÉ™ AzÉ™rbaycan dilindÉ™ sÃ¶hbÉ™t edin!

**Sabah gÃ¶rÃ¼ÅŸÉ™nÉ™dÉ™k!** ğŸ‘‹ Sabah **Modelin PaylaÅŸÄ±lmasÄ± vÉ™ GitHub** mÃ¶vzusunu Ã¶yrÉ™nÉ™cÉ™yik.

***

**SÃ¶z SayÄ±:** 800 sÃ¶z.
