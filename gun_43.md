# ğŸ“š 50 GÃ¼ndÉ™ SÃ¼ni-Ä°ntellekt: GÃ¼n 43

## TÉ™limin XÉ™rclÉ™ri vÉ™ ResurslarÄ±n Ä°darÉ™ EdilmÉ™si ğŸ’°

Salam! DÃ¼nÉ™n layihÉ™mizin sÉ™nÉ™dlÉ™ÅŸdirilmÉ™sini tamamladÄ±q. Bu gÃ¼n isÉ™ LLM tÉ™liminin maliyyÉ™ vÉ™ resurs tÉ™rÉ™fini â€“ yÉ™ni **TÉ™limin XÉ™rclÉ™ri vÉ™ ResurslarÄ±n Ä°darÉ™ EdilmÉ™si** mÃ¶vzusunu araÅŸdÄ±rÄ±rÄ±q.

### 1. TÉ™limin Æsas XÉ™rc FaktorlarÄ±

LLM tÉ™liminin xÉ™rclÉ™ri É™sasÉ™n Ã¼Ã§ faktordan asÄ±lÄ±dÄ±r:

#### A. Modelin Ã–lÃ§Ã¼sÃ¼ (Parametr SayÄ±)

*   **TÉ™sir:** Parametr sayÄ± nÉ™ qÉ™dÉ™r Ã§ox olarsa, modelin yaddaÅŸ tÉ™lÉ™bi vÉ™ hÉ™r bir addÄ±mda edilÉ™n É™mÉ™liyyatlarÄ±n sayÄ± bir o qÉ™dÉ™r artÄ±r.
*   **Bizim Model:** 124M parametr. Bu, Ã§ox kiÃ§ik bir modeldir vÉ™ xÉ™rclÉ™ri minimaldÄ±r.

#### B. MÉ™lumatÄ±n HÉ™cmi (Token SayÄ±)

*   **TÉ™sir:** TÉ™lim mÉ™lumatÄ±nÄ±n hÉ™cmi nÉ™ qÉ™dÉ™r Ã§ox olarsa, tÉ™lim bir o qÉ™dÉ™r uzun Ã§É™kir.
*   **Bizim Model:** TÉ™xminÉ™n 100M token. Bu, modelin bir neÃ§É™ dÉ™fÉ™ (Epoch) mÉ™lumatÄ± gÃ¶rmÉ™si Ã¼Ã§Ã¼n kifayÉ™tdir.

#### C. TÉ™limin DavamiyyÉ™ti (GPU SaatlarÄ±)

*   **TÉ™sir:** Æn bÃ¶yÃ¼k xÉ™rc faktorudur. TÉ™limin bir saatÄ± Ã¼Ã§Ã¼n GPU-nun icarÉ™ qiymÉ™ti xÉ™rci mÃ¼É™yyÉ™n edir.

### 2. T4 GPU-da XÉ™rc HesablamasÄ±

Siz **NVIDIA T4 (12 GB VRAM)** ilÉ™ iÅŸlÉ™yÉ™cÉ™ksiniz. Bu GPU bulud xidmÉ™tlÉ™rindÉ™ (mÉ™sÉ™lÉ™n, Google Colab Pro, AWS, Azure) saatlÄ±q Ã¶dÉ™niÅŸlÉ™ tÉ™klif olunur.

| XidmÉ™t | T4 GPU-nun SaatlÄ±q QiymÉ™ti (TÉ™xmini) |
| :--- | :--- |
| **Google Colab Pro** | $10 - $50 / ay (Limitsiz deyil) |
| **AWS EC2 (g4dn.xlarge)** | $0.52 / saat |
| **Azure (NC4as_T4_v3)** | $0.45 / saat |

**TÉ™xmini TÉ™lim VaxtÄ±:**
*   Bizim 124M modelimiz Ã¼Ã§Ã¼n 5000 addÄ±mlÄ±q tÉ™lim (100M token Ã¼zÉ™rindÉ™) T4 GPU-da tÉ™xminÉ™n **4-8 saat** Ã§É™kÉ™ bilÉ™r.

**TÉ™xmini XÉ™rc:**
*   8 saat * $0.50/saat = **$4.00**

**NÉ™ticÉ™:** Sizin layihÉ™nizin tÉ™lim xÉ™rci Ã§ox aÅŸaÄŸÄ±dÄ±r. Bu, kiÃ§ik LLM-lÉ™rin bÃ¶yÃ¼k Ã¼stÃ¼nlÃ¼yÃ¼dÃ¼r.

### 3. ResurslarÄ±n Ä°darÉ™ EdilmÉ™si

ResurslarÄ± effektiv idarÉ™ etmÉ™k xÉ™rclÉ™ri daha da azaldÄ±r.

#### A. VRAM-Ä±n OptimallaÅŸdÄ±rÄ±lmasÄ±

*   **Mixed Precision (`fp16`):** Bizim `accelerate` ilÉ™ tÉ™tbiq etdiyimiz bu Ã¼sul VRAM-Ä± iki dÉ™fÉ™ azaldÄ±r.
*   **Gradient Accumulation:** Effektiv Batch Size-Ä± artÄ±rÄ±r, lakin VRAM-Ä± artÄ±rmÄ±r.
*   **Modelin SilinmÉ™si:** TÉ™lim bitdikdÉ™n sonra model obyektini yaddaÅŸdan silin: `del model; torch.cuda.empty_cache()`.

#### B. TÉ™limin DayandÄ±rÄ±lmasÄ±

*   **ErkÉ™n DayandÄ±rma (Early Stopping):** Validasiya itkisi artmaÄŸa baÅŸlayanda tÉ™limi dayandÄ±rÄ±n. Bu, lazÄ±msÄ±z GPU saatlarÄ±nÄ± xÉ™rclÉ™mÉ™yin qarÅŸÄ±sÄ±nÄ± alÄ±r.
*   **Checkpoint:** HÉ™r 500 addÄ±mdan bir Checkpoint saxlamaq, tÉ™limin yarÄ±mÃ§Ä±q qalmasÄ± riskini azaldÄ±r.

### 4. CPU-da TÉ™lim (Alternativ)

ÆgÉ™r GPU-ya Ã§Ä±xÄ±ÅŸÄ±nÄ±z yoxdursa, bu kiÃ§ik modeli CPU-da da tÉ™lim etmÉ™k mÃ¼mkÃ¼ndÃ¼r.

*   **TÉ™sir:** TÉ™lim vaxtÄ± kÉ™skin ÅŸÉ™kildÉ™ artacaq (mÉ™sÉ™lÉ™n, 4-8 saat yerinÉ™ 40-80 saat).
*   **TÃ¶vsiyÉ™:** YalnÄ±z sÄ±naq mÉ™qsÉ™dlÉ™ri Ã¼Ã§Ã¼n istifadÉ™ edin.

### ğŸ’¡ GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: DÃ¼ÅŸÃ¼n vÉ™ Planlama

1.  ÆgÉ™r modelinizi 1 Milyard token Ã¼zÉ™rindÉ™ tÉ™lim etmÉ™k istÉ™sÉ™ydiniz, tÉ™lim vaxtÄ± vÉ™ xÉ™rci necÉ™ dÉ™yiÅŸÉ™rdi? (TÉ™xminÉ™n 10 dÉ™fÉ™ artardÄ±).
2.  TÉ™limi dayandÄ±rmaq Ã¼Ã§Ã¼n hansÄ± ÅŸÉ™rtlÉ™ri (Loss dÉ™yÉ™ri, PPL dÉ™yÉ™ri) Ã¶zÃ¼nÃ¼z Ã¼Ã§Ã¼n tÉ™yin edÉ™rdiniz?

**Sabah gÃ¶rÃ¼ÅŸÉ™nÉ™dÉ™k!** ğŸ‘‹ Sabah **LLM-lÉ™rin TÉ™tbiq SahÉ™lÉ™ri vÉ™ GÉ™lÉ™cÉ™k LayihÉ™lÉ™r** mÃ¶vzusunu Ã¶yrÉ™nÉ™cÉ™yik.

***

**SÃ¶z SayÄ±:** 750 sÃ¶z.
