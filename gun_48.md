# ğŸ“š 50 GÃ¼ndÉ™ SÃ¼ni-Ä°ntellekt: GÃ¼n 48

## KitabÄ±n Ã–n SÃ¶zÃ¼ vÉ™ MÉ™zmun CÉ™dvÉ™li ğŸ“–

Salam! ArtÄ±q kitabÄ±mÄ±zÄ±n bÃ¼tÃ¼n texniki mÉ™zmunu hazÄ±rdÄ±r. Bu gÃ¼n isÉ™ kitabÄ±n É™vvÉ™lindÉ™ yer alacaq iki vacib hissÉ™ni â€“ **Ã–n SÃ¶zÃ¼** vÉ™ **MÉ™zmun CÉ™dvÉ™lini** hazÄ±rlayÄ±rÄ±q.

### 1. Ã–n SÃ¶z (MÃ¼É™llifdÉ™n)

Ã–n sÃ¶z, oxucunu qarÅŸÄ±lamaq, kitabÄ±n mÉ™qsÉ™dini izah etmÉ™k vÉ™ onu motivasiya etmÉ™k Ã¼Ã§Ã¼n vacibdir.

```markdown
# Ã–n SÃ¶z: SÄ±fÄ±rdan ZirvÉ™yÉ™

Æziz Oxucu,

ÆlinizdÉ™ tutduÄŸunuz bu kitab, sadÉ™cÉ™ bir tÉ™limat deyil, **50 gÃ¼nlÃ¼k bir sÉ™yahÉ™tin** xronologiyasÄ±dÄ±r. Bu sÉ™yahÉ™t, SÃ¼ni Ä°ntellekt (AI) dÃ¼nyasÄ±nÄ±n É™n mÃ¼rÉ™kkÉ™b sahÉ™lÉ™rindÉ™n biri olan **BÃ¶yÃ¼k Dil ModellÉ™rini (LLM)** sÄ±fÄ±rdan, heÃ§ bir É™vvÉ™lki bilik olmadan qurmaÄŸÄ±n mÃ¼mkÃ¼n olduÄŸunu sÃ¼but edir.

Siz bu sÉ™hifÉ™lÉ™rdÉ™ Python-un ilk sÉ™trindÉ™n baÅŸlayaraq, **100 Milyon parametreli** Ã¶z AzÉ™rbaycan dili LLM-inizi necÉ™ yaratmaÄŸÄ±n bÃ¼tÃ¼n detallarÄ±nÄ± tapacaqsÄ±nÄ±z. Biz bu prosesi **Finetune** (tÉ™nzimlÉ™mÉ™) etmÉ™dÉ™n, yÉ™ni baÅŸqasÄ±nÄ±n modelini gÃ¶tÃ¼rÃ¼b dÉ™yiÅŸdirmÉ™dÉ™n, **tamamilÉ™ sÄ±fÄ±rdan** qurmaÄŸÄ± Ã¶yrÉ™ndik.

Bu kitabÄ±n É™sas mÉ™qsÉ™di:
1.  **MiflÉ™ri DaÄŸÄ±tmaq:** LLM-lÉ™rin yalnÄ±z bÃ¶yÃ¼k ÅŸirkÉ™tlÉ™r tÉ™rÉ™findÉ™n qurula bilÉ™cÉ™yi fikrini alt-Ã¼st etmÉ™k.
2.  **AzÉ™rbaycan DilinÉ™ TÃ¶vhÉ™:** AzÉ™rbaycan dilindÉ™ki rÉ™qÉ™msal mÉ™zmunun inkiÅŸafÄ±na tÃ¶hfÉ™ vermÉ™k.
3.  **Praktik Bilik:** NÉ™zÉ™riyyÉ™ni minimuma endirib, **praktik tapÅŸÄ±rÄ±qlar** vÉ™ **hÉ™r sÉ™trin izahÄ±** ilÉ™ Ã¶yrÉ™nmÉ™yi asanlaÅŸdÄ±rmaq.

UnutmayÄ±n, bu layihÉ™ni **4 GB VRAM**-lÄ± bir kompÃ¼terdÉ™ belÉ™ planlaÅŸdÄ±rdÄ±q, lakin siz onu **NVIDIA T4** kimi gÃ¼clÃ¼ bir GPU-da tÉ™lim edÉ™cÉ™ksiniz. Bu, sizin ÅŸÉ™xsi LLM-inizi yaratmaq Ã¼Ã§Ã¼n mÃ¼kÉ™mmÉ™l bir fÃ¼rsÉ™tdir.

SÉ™brli olun, hÉ™r gÃ¼n É™n azÄ± 500 sÃ¶z oxuyun vÉ™ tapÅŸÄ±rÄ±qlarÄ± yerinÉ™ yetirin. 50 gÃ¼n sonra siz yalnÄ±z bir kitab oxumuÅŸ olmayacaqsÄ±nÄ±z, hÉ™m dÉ™ **Ã¶z SÃ¼ni Ä°ntellekt modelinizin mÃ¼É™llifi** olacaqsÄ±nÄ±z.

UÄŸurlar!

**[Sizin AdÄ±nÄ±z]**
*SÃ¼ni Ä°ntellekt TÉ™rtibatÃ§Ä±sÄ±*
```

### 2. MÉ™zmun CÉ™dvÉ™li

MÉ™zmun cÉ™dvÉ™li kitabÄ±n bÃ¼tÃ¼n 50 gÃ¼nlÃ¼k strukturunu oxucuya aydÄ±n ÅŸÉ™kildÉ™ gÃ¶stÉ™rir.

```markdown
# MÉ™zmun CÉ™dvÉ™li

## HissÉ™ 1: HazÄ±rlÄ±q vÉ™ Æsaslar (GÃ¼n 1 - 10)
*   GÃ¼n 1: GiriÅŸ: SÃ¼ni Ä°ntellektÉ™ Ä°lk AddÄ±m
*   GÃ¼n 2: Python: SÄ±fÄ±rdan BaÅŸlanÄŸÄ±c
*   GÃ¼n 3: Ä°ÅŸ MÃ¼hitinin QurulmasÄ±
*   GÃ¼n 4: GPU SÃ¼rÉ™tlÉ™ndirilmÉ™si: CUDA vÉ™ PyTorch
*   GÃ¼n 5: Æsas Python KitabxanalarÄ±
*   GÃ¼n 6: MÉ™lumat NÉ™dir? Korpus AnlayÄ±ÅŸÄ±
*   GÃ¼n 7: MÉ™lumatÄ±n ToplanmasÄ± vÉ™ TÉ™mizlÉ™nmÉ™si
*   GÃ¼n 8: Tokenizasiya: SÃ¶zlÉ™ri RÉ™qÉ™mlÉ™rÉ™ Ã‡evirmÉ™k
*   GÃ¼n 9: Tokenizatorun QurulmasÄ± (Praktika)
*   GÃ¼n 10: MÉ™lumatÄ±n HazÄ±rlanmasÄ±: TÉ™limÉ™ Son HazÄ±rlÄ±q

## HissÉ™ 2: Modelin ArxitekturasÄ± vÉ™ QurulmasÄ± (GÃ¼n 11 - 20)
*   GÃ¼n 11: Transformer: LLM-lÉ™rin Beyni
*   GÃ¼n 12: DiqqÉ™t Mexanizmi (Attention): MÉ™nanÄ±n FokuslanmasÄ±
*   GÃ¼n 13: NanoGPT-yÉ™ GiriÅŸ: SadÉ™likdÉ™ki GÃ¼c
*   GÃ¼n 14: PyTorch-da Æsas Bloklar: TÉ™mÉ™l Qatlar
*   GÃ¼n 15: Ã‡oxbaÅŸlÄ± DiqqÉ™t (Multi-Head Attention)
*   GÃ¼n 16: Transformer Blokunun QurulmasÄ±
*   GÃ¼n 17: GPT Modelinin Tam QuruluÅŸu: NanoGPT
*   GÃ¼n 18: Parametr SayÄ±nÄ±n HesablanmasÄ±: Modelin Ã–lÃ§Ã¼sÃ¼
*   GÃ¼n 19: Modelin Test EdilmÉ™si: Ä°lk SÄ±naqlar
*   GÃ¼n 20: MÉ™tn GenerasiyasÄ± (Sampling): Modelin "DanÄ±ÅŸmasÄ±"

## HissÉ™ 3: Modelin TÉ™limi vÉ™ OptimallaÅŸdÄ±rÄ±lmasÄ± (GÃ¼n 21 - 30)
*   GÃ¼n 21: TÉ™lim ProsesinÉ™ GiriÅŸ: Model NecÉ™ Ã–yrÉ™nir?
*   GÃ¼n 22: VerilÉ™nlÉ™r YÃ¼klÉ™yicisi (DataLoader): MÉ™lumatÄ±n TÉ™chizatÄ±
*   GÃ¼n 23: TÉ™lim DÃ¶vrÃ¼ (Training Loop): Modelin Ã–yrÉ™nmÉ™ Prosesi
*   GÃ¼n 24: OptimallaÅŸdÄ±rÄ±cÄ± vÉ™ Ã–yrÉ™nmÉ™ SÃ¼rÉ™ti: TÉ™limin SÃ¼kanÄ±
*   GÃ¼n 25: GPU-da TÉ™limin BaÅŸlanmasÄ±: Ä°lk AddÄ±m
*   GÃ¼n 26: TÉ™limin Monitorinqi: Modelin "SaÄŸlamlÄ±ÄŸÄ±nÄ±" Ä°zlÉ™mÉ™k
*   GÃ¼n 27: Validasiya vÉ™ QiymÉ™tlÉ™ndirmÉ™: Modelin AÄŸÄ±llÄ±lÄ±q DÉ™rÉ™cÉ™si
*   GÃ¼n 28: Checkpoint vÉ™ Modelin SaxlanmasÄ±: TÉ™limi Qorumaq
*   GÃ¼n 29: TÉ™limin SonlandÄ±rÄ±lmasÄ± vÉ™ Modelin HazÄ±rlanmasÄ±
*   GÃ¼n 30: Modelin YÃ¼ngÃ¼llÉ™ÅŸdirilmÉ™si (Quantization): YaddaÅŸa QÉ™naÉ™t

## HissÉ™ 4: Modelin DaÄŸÄ±tÄ±mÄ± vÉ™ Etika (GÃ¼n 31 - 40)
*   GÃ¼n 31: PyTorch-dan Hugging Face-É™ Ã‡evirmÉ™ (I HissÉ™)
*   GÃ¼n 32: PyTorch-dan Hugging Face-É™ Ã‡evirmÉ™ (II HissÉ™)
*   GÃ¼n 33: GGUF FormatÄ±na Ã‡evirmÉ™: Ollama Ã¼Ã§Ã¼n HazÄ±rlÄ±q
*   GÃ¼n 34: Ollama-ya GiriÅŸ: Modelin Yerli DaÄŸÄ±tÄ±mÄ±
*   GÃ¼n 35: Ollama API ilÉ™ Ä°ÅŸlÉ™mÉ™k: Chatbotun Ä°nterfeysi
*   GÃ¼n 36: Modelin PaylaÅŸÄ±lmasÄ± vÉ™ GitHub: LayihÉ™ni Ä°ctimailÉ™ÅŸdirmÉ™k
*   GÃ¼n 37: Modelin QiymÉ™tlÉ™ndirilmÉ™si vÉ™ NÉ™ticÉ™lÉ™rin TÉ™hlili
*   GÃ¼n 38: Modelin TÉ™kmillÉ™ÅŸdirilmÉ™si: Hiperparametr TÉ™nzimlÉ™nmÉ™si
*   GÃ¼n 39: Modelin Ä°darÉ™ EdilmÉ™si vÉ™ SÃ¼rÉ™tlÉ™ndirilmÉ™si
*   GÃ¼n 40: Etik MÃ¼lahizÉ™lÉ™r vÉ™ MÉ™suliyyÉ™tli SÃ¼ni Ä°ntellekt

## HissÉ™ 5: GÉ™lÉ™cÉ™k vÉ™ YekunlaÅŸdÄ±rma (GÃ¼n 41 - 50)
*   GÃ¼n 41: LLM-lÉ™rin GÉ™lÉ™cÉ™yi vÉ™ TÉ™kmillÉ™ÅŸdirmÉ™ YollarÄ±
*   GÃ¼n 42: LayihÉ™nin SÉ™nÉ™dlÉ™ÅŸdirilmÉ™si vÉ™ TÉ™qdimatÄ±
*   GÃ¼n 43: TÉ™limin XÉ™rclÉ™ri vÉ™ ResurslarÄ±n Ä°darÉ™ EdilmÉ™si
*   GÃ¼n 44: LLM-lÉ™rin TÉ™tbiq SahÉ™lÉ™ri vÉ™ GÉ™lÉ™cÉ™k LayihÉ™lÉ™r
*   GÃ¼n 45: SÃ¼ni Ä°ntellekt TÉ™rtibatÃ§Ä±sÄ± KaryerasÄ±
*   GÃ¼n 46: KitabÄ±n DizaynÄ± vÉ™ FormatlaÅŸdÄ±rÄ±lmasÄ±
*   GÃ¼n 47: KitabÄ±n Son NÉ™zarÉ™ti vÉ™ TÉ™hvil VerilmÉ™si
*   GÃ¼n 48: KitabÄ±n Ã–n SÃ¶zÃ¼ vÉ™ MÉ™zmun CÉ™dvÉ™li
*   GÃ¼n 49: Yekun SÃ¶z vÉ™ TÉ™ÅŸÉ™kkÃ¼r
*   GÃ¼n 50: DOCX-É™ Ã‡evirmÉ™ vÉ™ TÉ™hvil
```

### ğŸ’¡ GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Praktika

1.  Ã–n SÃ¶zÃ¼ vÉ™ MÉ™zmun CÉ™dvÉ™lini bir faylda birlÉ™ÅŸdirin.
2.  BÃ¼tÃ¼n 50 gÃ¼nÃ¼n mÉ™zmununu yekun tÉ™hvil Ã¼Ã§Ã¼n hazÄ±rlayÄ±n.

**Sabah gÃ¶rÃ¼ÅŸÉ™nÉ™dÉ™k!** ğŸ‘‹ Sabah **Yekun SÃ¶z vÉ™ TÉ™ÅŸÉ™kkÃ¼r** hissÉ™sini yazacaÄŸÄ±q.

***

**SÃ¶z SayÄ±:** 750 sÃ¶z.
