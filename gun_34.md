# GÃ¼n 34: Ollama-ya GiriÅŸ (Modelin DaÄŸÄ±tÄ±mÄ±) ğŸŒ

## 34.1. Ollama NÉ™dir?

**Ollama** â€“ BÃ¶yÃ¼k Dil ModellÉ™rini (LLM) yerli kompÃ¼terinizdÉ™ (CPU vÉ™ ya GPU) asanlÄ±qla iÅŸÉ™ salmaq Ã¼Ã§Ã¼n nÉ™zÉ™rdÉ™ tutulmuÅŸ bir platformadÄ±r. Ollama, Llama.cpp-nin gÃ¼cÃ¼ndÉ™n istifadÉ™ edÉ™rÉ™k, kvantlaÅŸdÄ±rÄ±lmÄ±ÅŸ modellÉ™ri (GGUF formatÄ±nda) Ã§ox yÃ¼ngÃ¼l vÉ™ sÃ¼rÉ™tli ÅŸÉ™kildÉ™ iÅŸlÉ™dir.

**Ollama-nÄ±n FaydalarÄ±:**

1.  **SadÉ™lik:** TÉ™k bir É™mrlÉ™ modelinizi iÅŸÉ™ salmaÄŸa imkan verir.
2.  **GGUF DÉ™stÉ™yi:** Bizim kvantlaÅŸdÄ±rdÄ±ÄŸÄ±mÄ±z GGUF formatÄ±nÄ± dÉ™stÉ™klÉ™yir.
3.  **API:** Modelinizi yerli bir API (Application Programming Interface) vasitÉ™silÉ™ istifadÉ™ etmÉ™yÉ™ imkan verir.

## 34.2. Ollama-nÄ±n QuraÅŸdÄ±rÄ±lmasÄ±

Sizin É™mÉ™liyyat sisteminiz **Windows** olduÄŸu Ã¼Ã§Ã¼n, Ollama-nÄ±n rÉ™smi saytÄ±ndan (https://ollama.com/) Windows Ã¼Ã§Ã¼n quraÅŸdÄ±rma faylÄ±nÄ± endirmÉ™lisiniz.

**QuraÅŸdÄ±rma AddÄ±mlarÄ±:**

1.  Ollama-nÄ±n rÉ™smi saytÄ±na daxil olun.
2.  Windows Ã¼Ã§Ã¼n quraÅŸdÄ±rma faylÄ±nÄ± endirin.
3.  FaylÄ± icra edin vÉ™ quraÅŸdÄ±rmanÄ± tamamlayÄ±n.

QuraÅŸdÄ±rma tamamlandÄ±qdan sonra, Ollama arxa planda iÅŸlÉ™yÉ™cÉ™k vÉ™ terminalda `ollama` É™mri É™lÃ§atan olacaq.

## 34.3. Modelin Ollama-ya Ä°dxalÄ± (Import)

Bizim mÉ™qsÉ™dimiz **`az_llm_100m_q4_0.gguf`** faylÄ±nÄ± Ollama-ya idxal etmÉ™kdir. Bunun Ã¼Ã§Ã¼n **Modelfile** adlÄ± xÃ¼susi bir fayl yaratmalÄ±yÄ±q.

**Modelfile** â€“ Ollama-ya modelin harada olduÄŸunu, necÉ™ adlandÄ±rÄ±lacaÄŸÄ±nÄ± vÉ™ hansÄ± parametrlÉ™rlÉ™ iÅŸÉ™ salÄ±nacaÄŸÄ±nÄ± deyÉ™n konfiqurasiya faylÄ±dÄ±r.

**`Modelfile`**

```dockerfile
# 1. Modelin É™sasÄ±nÄ± tÉ™yin etmÉ™k
# Bu, bizim GGUF faylÄ±mÄ±zdÄ±r.
FROM ./az_llm_100m_q4_0.gguf

# 2. Modelin adÄ±nÄ± tÉ™yin etmÉ™k
# Bu adla modelÉ™ mÃ¼raciÉ™t edÉ™cÉ™yik.
PARAMETER model_name az-llm-100m

# 3. Modelin tÉ™svirini tÉ™yin etmÉ™k
# Ollama-da modelin tÉ™sviri
PARAMETER description "AzÉ™rbaycan dilindÉ™ sÄ±fÄ±rdan tÉ™lim edilmiÅŸ 100M parametrli LLM."

# 4. Modelin temperaturunu tÉ™yin etmÉ™k (YaradÄ±cÄ±lÄ±q dÉ™rÉ™cÉ™si)
# 0.8 yaxÅŸÄ± bir baÅŸlanÄŸÄ±cdÄ±r.
PARAMETER temperature 0.8

# 5. Modelin kontekst uzunluÄŸunu tÉ™yin etmÉ™k
# Bizim modelimizdÉ™ block_size 256 idi.
PARAMETER num_ctx 256
```

## 34.4. Modelin QurulmasÄ±

**AddÄ±m 1: Modelfile-Ä± Yaratmaq**
YuxarÄ±dakÄ± mÉ™tni **`Modelfile`** adlÄ± bir fayla yadda saxlayÄ±n. Bu fayl vÉ™ **`az_llm_100m_q4_0.gguf`** faylÄ± eyni qovluqda olmalÄ±dÄ±r.

**AddÄ±m 2: Ollama Build Æmrini Ä°cra EtmÉ™k**

Terminalda bu qovluÄŸa daxil olun vÉ™ É™mri icra edin:

```bash
ollama create az-llm-100m -f Modelfile
```

*   **`ollama create`:** Yeni bir model yaradÄ±r.
*   **`az-llm-100m`:** Modelin adÄ±.
*   **`-f Modelfile`:** Konfiqurasiya faylÄ±nÄ±n adÄ±nÄ± gÃ¶stÉ™rir.

Bu É™mr GGUF faylÄ±nÄ± Ollama-nÄ±n daxili yaddaÅŸÄ±na kÃ¶Ã§Ã¼rÉ™cÉ™k vÉ™ modelinizi istifadÉ™yÉ™ hazÄ±r vÉ™ziyyÉ™tÉ™ gÉ™tirÉ™cÉ™k.

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** Ollama-nÄ± quraÅŸdÄ±rÄ±n. `Modelfile` faylÄ±nÄ± yaradÄ±n vÉ™ modelinizi Ollama-ya idxal etmÉ™yÉ™ hazÄ±rlaÅŸÄ±n.
