# GÃ¼n 34: Ollama-ya GiriÅŸ (Modelin DaÄŸÄ±tÄ±mÄ±) ğŸŒ

## 34.1. Ollama PlatformasÄ±nÄ±n ÆhÉ™miyyÉ™ti

**Ollama** â€“ BÃ¶yÃ¼k Dil ModellÉ™rini (LLM) yerli kompÃ¼terdÉ™ (CPU vÉ™ ya GPU) asanlÄ±qla iÅŸÉ™ salmaq Ã¼Ã§Ã¼n nÉ™zÉ™rdÉ™ tutulmuÅŸ bir platformadÄ±r. Ollama, Llama.cpp-nin gÃ¼cÃ¼ndÉ™n istifadÉ™ edÉ™rÉ™k, kvantlaÅŸdÄ±rÄ±lmÄ±ÅŸ modellÉ™ri (GGUF formatÄ±nda) yÃ¼ngÃ¼l vÉ™ sÃ¼rÉ™tli ÅŸÉ™kildÉ™ iÅŸlÉ™dir.

**MÉ™ntiq:** Ollama, LLM-lÉ™rin istifadÉ™sini sadÉ™lÉ™ÅŸdirÉ™n bir interfeys tÉ™min edir. Bu, modelin tÉ™limindÉ™n sonra onu son istifadÉ™Ã§iyÉ™ Ã§atdÄ±rmaq Ã¼Ã§Ã¼n É™n effektiv yoldur.

## 34.2. Ollama-nÄ±n QuraÅŸdÄ±rÄ±lmasÄ±

Ollama-nÄ±n quraÅŸdÄ±rÄ±lmasÄ± É™mÉ™liyyat sistemindÉ™n asÄ±lÄ±dÄ±r (Windows, macOS, Linux). RÉ™smi saytdan (https://ollama.com/) uyÄŸun quraÅŸdÄ±rma faylÄ± endirilmÉ™lidir.

**QuraÅŸdÄ±rma MÉ™ntiqi:** Ollama quraÅŸdÄ±rÄ±ldÄ±qdan sonra, arxa planda iÅŸlÉ™yÉ™n bir server (adÉ™tÉ™n 11434 portunda) iÅŸÉ™ salÄ±r vÉ™ bu server vasitÉ™silÉ™ modellÉ™rÉ™ mÃ¼raciÉ™t etmÉ™k mÃ¼mkÃ¼n olur.

## 34.3. Modelin Ollama-ya Ä°dxalÄ± (Modelfile)

Ollama-ya model idxal etmÉ™k Ã¼Ã§Ã¼n **Modelfile** adlÄ± xÃ¼susi bir konfiqurasiya faylÄ± tÉ™lÉ™b olunur. Bu fayl Ollama-ya modelin harada olduÄŸunu vÉ™ hansÄ± parametrlÉ™rlÉ™ iÅŸÉ™ salÄ±nacaÄŸÄ±nÄ± bildirir.

**`Modelfile`**

```dockerfile
# 1. Modelin É™sasÄ±nÄ± tÉ™yin etmÉ™k
# Bu, bizim GGUF faylÄ±mÄ±zdÄ±r.
FROM ./az_llm_100m_q4_0.gguf

# 2. Modelin adÄ±nÄ± tÉ™yin etmÉ™k
PARAMETER model_name az-llm-100m

# 3. Modelin tÉ™svirini tÉ™yin etmÉ™k
PARAMETER description "AzÉ™rbaycan dilindÉ™ sÄ±fÄ±rdan tÉ™lim edilmiÅŸ 100M parametrli, 4-bit kvantlaÅŸdÄ±rÄ±lmÄ±ÅŸ LLM."

# 4. Modelin temperaturunu tÉ™yin etmÉ™k (YaradÄ±cÄ±lÄ±q dÉ™rÉ™cÉ™si)
# 0.8 yaxÅŸÄ± bir baÅŸlanÄŸÄ±cdÄ±r.
PARAMETER temperature 0.8

# 5. Modelin kontekst uzunluÄŸunu tÉ™yin etmÉ™k
# Bizim modelimizdÉ™ block_size 256 idi.
PARAMETER num_ctx 256

# 6. Modelin davranÄ±ÅŸÄ±nÄ± tÉ™yin edÉ™n sistem tÉ™limatÄ±
PARAMETER system "SÉ™n AzÉ™rbaycan dilindÉ™ danÄ±ÅŸan, dostyana vÉ™ mÉ™lumatlÄ± bir sÃ¼ni intellekt kÃ¶mÉ™kÃ§isisÉ™n. CavablarÄ±n qÄ±sa vÉ™ mÉ™ntiqli olsun."
```

## 34.4. Modelin QurulmasÄ± Æmri

**AddÄ±m 1:** `Modelfile` vÉ™ `az_llm_100m_q4_0.gguf` fayllarÄ± eyni qovluqda yerlÉ™ÅŸdirilir.

**AddÄ±m 2:** Terminalda `ollama create` É™mri icra edilir.

```bash
ollama create az-llm-100m -f Modelfile
```

*   **`ollama create`:** Yeni bir model yaradÄ±r.
*   **`az-llm-100m`:** Modelin Ollama daxilindÉ™ki adÄ±.
*   **`-f Modelfile`:** Konfiqurasiya faylÄ±nÄ±n adÄ±nÄ± gÃ¶stÉ™rir.

**MÉ™ntiq:** Bu É™mr GGUF faylÄ±nÄ± Ollama-nÄ±n daxili yaddaÅŸÄ±na kÃ¶Ã§Ã¼rÃ¼r vÉ™ modelin parametrlÉ™rini tÉ™tbiq edir. Model artÄ±q yerli kompÃ¼terdÉ™ istifadÉ™ Ã¼Ã§Ã¼n hazÄ±rdÄ±r.
