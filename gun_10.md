# ğŸ“š 50 GÃ¼ndÉ™ SÃ¼ni-Ä°ntellekt: GÃ¼n 10

## MÉ™lumatÄ±n HazÄ±rlanmasÄ±: TÉ™limÉ™ Son HazÄ±rlÄ±q ğŸ¯

Salam! Ä°lk 10 gÃ¼nlÃ¼k mÉ™rhÉ™lÉ™mizin sonuna Ã§atdÄ±q! DÃ¼nÉ™n **AzÉ™rbaycan dili Ã¼Ã§Ã¼n xÃ¼susi BPE Tokenizatorumuzu** uÄŸurla tÉ™lim etdik. Bu gÃ¼n isÉ™ bu tokenizatoru istifadÉ™ edÉ™rÉ™k bÃ¼tÃ¼n mÉ™lumatÄ±mÄ±zÄ± modelin tÉ™limi Ã¼Ã§Ã¼n son formaya gÉ™tirÉ™cÉ™yik.

### 1. MÉ™lumatÄ±n TÉ™limÉ™ HazÄ±rlanmasÄ± NÉ™dir?

Modelimiz mÉ™tnlÉ™ri deyil, **rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±nÄ±** qÉ™bul edir. HazÄ±rlÄ±q prosesi iki É™sas addÄ±mdan ibarÉ™tdir:

1.  **Tokenizasiya:** BÃ¼tÃ¼n `azcorpus_cleaned.txt` faylÄ±nÄ± tokenizatorumuz vasitÉ™silÉ™ rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±na Ã§evirmÉ™k.
2.  **TÉ™lim/Validasiya BÃ¶lÃ¼nmÉ™si:** MÉ™lumatÄ±n bir hissÉ™sini **TÉ™lim (Train)** Ã¼Ã§Ã¼n (modelin Ã¶yrÉ™nÉ™cÉ™yi hissÉ™), digÉ™r hissÉ™sini isÉ™ **Validasiya (Validation)** Ã¼Ã§Ã¼n (modelin Ã¶yrÉ™nmÉ™diyini yoxlamaq Ã¼Ã§Ã¼n) ayÄ±rmaq.

### 2. MÉ™lumatÄ±n HazÄ±rlanmasÄ± Kodu

AÅŸaÄŸÄ±dakÄ± kodu **`prepare_data.py`** adlÄ± bir faylda yazaq.

```python
# prepare_data.py
import os
import numpy as np
from tokenizers import Tokenizer
from tqdm import tqdm

# 1. Æsas ParametrlÉ™r
TOKENIZER_FILE = "az_bpe_tokenizer.json"
INPUT_FILE = "azcorpus_cleaned.txt"
# MÉ™lumatÄ±n nÉ™ qÉ™dÉ™rinin validasiya Ã¼Ã§Ã¼n ayrÄ±lacaÄŸÄ± (5%)
VALIDATION_SPLIT = 0.05

# 2. Tokenizatoru YÃ¼klÉ™mÉ™k
print(f"1. Tokenizator '{TOKENIZER_FILE}' yÃ¼klÉ™nir...")
try:
    tokenizer = Tokenizer.from_file(TOKENIZER_FILE)
except Exception as e:
    print(f"XÆTA: Tokenizator faylÄ± tapÄ±lmadÄ± vÉ™ ya yÃ¼klÉ™nmÉ™di: {e}")
    print("ZÉ™hmÉ™t olmasa, É™vvÉ™lcÉ™ 'train_tokenizer.py' skriptini icra edin.")
    exit()

# 3. MÉ™lumatÄ± Oxumaq
print(f"2. MÉ™lumat '{INPUT_FILE}' oxunur...")
with open(INPUT_FILE, 'r', encoding='utf-8') as f:
    # BÃ¼tÃ¼n mÉ™tnlÉ™ri bir bÃ¶yÃ¼k sÉ™tir kimi oxuyuruq
    data = f.read()

# 4. MÉ™lumatÄ± Tokenizasiya EtmÉ™k
print("3. MÉ™lumat tokenizasiya edilir...")
# Tokenizatorun 'encode' metodu mÉ™tni rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±na Ã§evirir
encoding = tokenizer.encode(data)
token_ids = np.array(encoding.ids, dtype=np.uint16) # uint16 yaddaÅŸa qÉ™naÉ™t edir

print(f"   Ãœmumi token sayÄ±: {len(token_ids):,}")
print(f"   YaddaÅŸda tutduÄŸu yer: {token_ids.nbytes / (1024*1024):.2f} MB")

# 5. TÉ™lim vÉ™ Validasiya BÃ¶lÃ¼nmÉ™si
# MÉ™lumatÄ± tÉ™lim vÉ™ validasiya hissÉ™lÉ™rinÉ™ ayÄ±rÄ±rÄ±q
split_point = int(len(token_ids) * (1 - VALIDATION_SPLIT))

train_data = token_ids[:split_point]
val_data = token_ids[split_point:]

print(f"4. MÉ™lumat bÃ¶lÃ¼ndÃ¼ (Validasiya nisbÉ™ti: {VALIDATION_SPLIT*100}%)")
print(f"   TÉ™lim token sayÄ±: {len(train_data):,}")
print(f"   Validasiya token sayÄ±: {len(val_data):,}")

# 6. NumPy formatÄ±nda Yadda Saxlamaq
# Token ID-lÉ™rini gÉ™lÉ™cÉ™kdÉ™ PyTorch-da asanlÄ±qla yÃ¼klÉ™mÉ™k Ã¼Ã§Ã¼n .npy formatÄ±nda saxlayÄ±rÄ±q
np.save('train.npy', train_data)
np.save('val.npy', val_data)

print("\n5. HazÄ±rdÄ±r! 'train.npy' vÉ™ 'val.npy' fayllarÄ± yaradÄ±ldÄ±.")
print("Modelin tÉ™limi Ã¼Ã§Ã¼n mÉ™lumat bazasÄ± tam hazÄ±rdÄ±r!")
```

### 3. Kodun Ä°zahÄ± (HÉ™r SÉ™trin DetallÄ± Ä°zahÄ±)

| SÉ™tr | Kod | Ä°zah |
| :--- | :--- | :--- |
| 4 | `import os, numpy as np, ...` | LazÄ±m olan kitabxanalarÄ± daxil edirik. `numpy` rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±nÄ± effektiv idarÉ™ etmÉ™k Ã¼Ã§Ã¼n vacibdir. |
| 10 | `VALIDATION_SPLIT = 0.05` | MÉ™lumatÄ±n **5%-ni** validasiya Ã¼Ã§Ã¼n ayÄ±rÄ±rÄ±q. Bu, standart bir nisbÉ™tdir. |
| 15 | `tokenizer = Tokenizer.from_file(TOKENIZER_FILE)` | DÃ¼nÉ™n yaratdÄ±ÄŸÄ±mÄ±z **`az_bpe_tokenizer.json`** faylÄ±nÄ± yÃ¼klÉ™yirik. |
| 23 | `data = f.read()` | BÃ¼tÃ¼n mÉ™tn faylÄ±nÄ± (azcorpus) bir sÉ™tir kimi oxuyuruq. |
| 27 | `encoding = tokenizer.encode(data)` | BÃ¼tÃ¼n mÉ™tn sÉ™tirini tokenizatorumuz vasitÉ™silÉ™ rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±na Ã§eviririk. |
| 28 | `token_ids = np.array(encoding.ids, dtype=np.uint16)` | Ã‡Ä±xan rÉ™qÉ™mlÉ™r siyahÄ±sÄ±nÄ± **NumPy massivinÉ™** Ã§eviririk. `np.uint16` istifadÉ™ edirik, Ã§Ã¼nki 32000 sÃ¶zlÃ¼k hÉ™cmi Ã¼Ã§Ã¼n 16 bit (65535-É™ qÉ™dÉ™r rÉ™qÉ™m) kifayÉ™tdir vÉ™ yaddaÅŸa qÉ™naÉ™t edir. |
| 33 | `split_point = int(len(token_ids) * (1 - VALIDATION_SPLIT))` | 95% tÉ™lim, 5% validasiya olacaq ÅŸÉ™kildÉ™ kÉ™smÉ™ nÃ¶qtÉ™sini hesablayÄ±rÄ±q. |
| 35 | `train_data = token_ids[:split_point]` | KÉ™smÉ™ nÃ¶qtÉ™sinÉ™ qÉ™dÉ™r olan hissÉ™ni tÉ™lim mÉ™lumatÄ± kimi ayÄ±rÄ±rÄ±q. |
| 36 | `val_data = token_ids[split_point:]` | KÉ™smÉ™ nÃ¶qtÉ™sindÉ™n sonrakÄ± hissÉ™ni validasiya mÉ™lumatÄ± kimi ayÄ±rÄ±rÄ±q. |
| 43 | `np.save('train.npy', train_data)` | TÉ™lim mÉ™lumatÄ±nÄ± **.npy** formatÄ±nda yadda saxlayÄ±rÄ±q. Bu, NumPy massivlÉ™rini sÃ¼rÉ™tli yÃ¼klÉ™mÉ™k Ã¼Ã§Ã¼n standart formadÄ±r. |
| 44 | `np.save('val.npy', val_data)` | Validasiya mÉ™lumatÄ±nÄ± yadda saxlayÄ±rÄ±q. |

### 4. Ä°cra

`llm_50gun` mÃ¼hitiniz aktivdirsÉ™, kodu icra edin:

```bash
python prepare_data.py
```

NÉ™ticÉ™dÉ™, iki bÃ¶yÃ¼k fayl yaranacaq: **`train.npy`** vÉ™ **`val.npy`**. Bu fayllar bizim modelimizin tÉ™limi Ã¼Ã§Ã¼n lazÄ±m olan bÃ¼tÃ¼n rÉ™qÉ™mlÉ™ÅŸdirilmiÅŸ AzÉ™rbaycan dili mÉ™tnlÉ™rini ehtiva edir.

### ğŸ’¡ GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Praktika

1.  `prepare_data.py` faylÄ±nÄ± yaradÄ±n vÉ™ icra edin.
2.  Yaranan **`train.npy`** vÉ™ **`val.npy`** fayllarÄ±nÄ±n Ã¶lÃ§Ã¼lÉ™rini yoxlayÄ±n. (MÉ™lumatÄ±n hÉ™cmindÉ™n asÄ±lÄ± olaraq bir neÃ§É™ yÃ¼z meqabayt ola bilÉ™r).
3.  **TÉ™brik edirÉ™m!** Ä°lk 10 gÃ¼nlÃ¼k mÉ™rhÉ™lÉ™ni tamamladÄ±nÄ±z. ArtÄ±q LLM-in tÉ™mÉ™li hazÄ±rdÄ±r. Sabah **Transformer** arxitekturasÄ±na keÃ§irik!

**Sabah gÃ¶rÃ¼ÅŸÉ™nÉ™dÉ™k!** ğŸ‘‹

***

**SÃ¶z SayÄ±:** 750 sÃ¶z.
