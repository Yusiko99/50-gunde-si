# GÃ¼n 10: Tokenizasiya I: SÃ¶zlÉ™ri RÉ™qÉ™mlÉ™rÉ™ Ã‡evirmÉ™k ğŸ”¢

## 10.1. TokenizasiyanÄ±n ZÉ™ruriliyi

Neyron ÅŸÉ™bÉ™kÉ™lÉ™ri mÉ™tnlÉ™ deyil, yalnÄ±z **rÉ™qÉ™mlÉ™rlÉ™** iÅŸlÉ™yÉ™ bilÉ™r. **Tokenizasiya** prosesi, insan dilindÉ™ki mÉ™tnin modelin baÅŸa dÃ¼ÅŸÉ™cÉ™yi rÉ™qÉ™msal ardÄ±cÄ±llÄ±qlara Ã§evrilmÉ™sidir.

**MÉ™ntiq:** HÉ™r bir unikal sÃ¶z, sÃ¶zÃ¼n hissÉ™si vÉ™ ya simvol (token) lÃ¼ÄŸÉ™tdÉ™ (Vocabulary) bir unikal tam É™dÉ™dÉ™ (ID) uyÄŸun gÉ™lir. Model bu ID-lÉ™ri giriÅŸ kimi qÉ™bul edir vÉ™ Ã§Ä±xÄ±ÅŸda nÃ¶vbÉ™ti tokenin ID-sini proqnozlaÅŸdÄ±rÄ±r.

## 10.2. Tokenizator NÃ¶vlÉ™ri

LLM-lÉ™rdÉ™ É™n Ã§ox istifadÉ™ olunan tokenizator nÃ¶vlÉ™ri aÅŸaÄŸÄ±dakÄ±lardÄ±r:

| NÃ¶v | MÉ™ntiqi Æsas | ÃœstÃ¼nlÃ¼yÃ¼ |
| :--- | :--- | :--- |
| **Word-based** | HÉ™r sÃ¶z bir tokendir. | SadÉ™dir. |
| **Character-based** | HÉ™r simvol bir tokendir. | LÃ¼ÄŸÉ™t kiÃ§ikdir, lakin ardÄ±cÄ±llÄ±qlar Ã§ox uzundur. |
| **Subword-based (BPE)** | SÃ¶zlÉ™ri tez-tez tÉ™krarlanan alt-vahidlÉ™rinÉ™ (subwords) bÃ¶lÃ¼r. | **LLM-lÉ™r Ã¼Ã§Ã¼n standartdÄ±r.** LÃ¼ÄŸÉ™t Ã¶lÃ§Ã¼sÃ¼ ilÉ™ ardÄ±cÄ±llÄ±q uzunluÄŸu arasÄ±nda optimal balans yaradÄ±r. |

Bizim modelimiz Ã¼Ã§Ã¼n **Subword-based (BPE - Byte Pair Encoding)** tokenizatoru istifadÉ™ edilÉ™cÉ™k.

## 10.3. Byte Pair Encoding (BPE) MÉ™ntiqi

BPE alqoritmi aÅŸaÄŸÄ±dakÄ± mÉ™ntiqÉ™ É™saslanÄ±r:

1.  **BaÅŸlanÄŸÄ±c:** BÃ¼tÃ¼n mÉ™tn simvollara bÃ¶lÃ¼nÃ¼r.
2.  **TÉ™krarlama:** Korpusda É™n Ã§ox tÉ™krarlanan bitiÅŸik simvol cÃ¼tÃ¼ (vÉ™ ya token cÃ¼tÃ¼) tapÄ±lÄ±r.
3.  **BirlÉ™ÅŸdirmÉ™:** TapÄ±lan cÃ¼t yeni bir token kimi lÃ¼ÄŸÉ™tÉ™ É™lavÉ™ edilir vÉ™ mÉ™tndÉ™ki bÃ¼tÃ¼n rast gÉ™linÉ™n yerlÉ™rdÉ™ bu yeni tokenlÉ™ É™vÉ™z edilir.
4.  **Son:** Bu proses, lÃ¼ÄŸÉ™t Ã¶lÃ§Ã¼sÃ¼ (Vocabulary Size) É™vvÉ™lcÉ™dÉ™n tÉ™yin edilmiÅŸ hÉ™ddÉ™ Ã§atana qÉ™dÉ™r tÉ™krarlanÄ±r.

**NÃ¼munÉ™:** "AzÉ™rbaycan" sÃ¶zÃ¼.

| AddÄ±m | Æn Ã‡ox TÉ™krarlanan CÃ¼t | NÉ™ticÉ™ |
| :--- | :--- | :--- |
| **BaÅŸlanÄŸÄ±c** | `A z É™ r b a y c a n` | Simvollar |
| **1** | `az` | `az` tokeni yaranÄ±r. |
| **2** | `an` | `an` tokeni yaranÄ±r. |
| **...** | | Yekunda: `AzÉ™r` + `bay` + `can` kimi alt-sÃ¶zlÉ™rÉ™ bÃ¶lÃ¼nÉ™ bilÉ™r. |

**MÉ™ntiq:** BPE, tez-tez rast gÉ™linÉ™n sÃ¶zlÉ™ri (mÉ™sÉ™lÉ™n, "kitab") tÉ™k bir token kimi, nadir sÃ¶zlÉ™ri (mÉ™sÉ™lÉ™n, "kitabxanaÃ§Ä±lÄ±q") isÉ™ bir neÃ§É™ tokenin birlÉ™ÅŸmÉ™si kimi kodlaÅŸdÄ±rÄ±r. Bu, lÃ¼ÄŸÉ™tin Ã¶lÃ§Ã¼sÃ¼nÃ¼ idarÉ™ etmÉ™yÉ™ vÉ™ namÉ™lum sÃ¶zlÉ™rin (OOV - Out-of-Vocabulary) qarÅŸÄ±sÄ±nÄ± almaÄŸa kÃ¶mÉ™k edir.

## 10.4. LÃ¼ÄŸÉ™t Ã–lÃ§Ã¼sÃ¼nÃ¼n SeÃ§ilmÉ™si

LLM-lÉ™r Ã¼Ã§Ã¼n lÃ¼ÄŸÉ™t Ã¶lÃ§Ã¼sÃ¼ adÉ™tÉ™n 30,000 ilÉ™ 50,000 arasÄ±nda seÃ§ilir. Bizim 100M parametrli modelimiz Ã¼Ã§Ã¼n **32,000 tokenlik** bir lÃ¼ÄŸÉ™t Ã¶lÃ§Ã¼sÃ¼ seÃ§ilÉ™cÉ™k.

**MÉ™ntiq:** LÃ¼ÄŸÉ™t nÉ™ qÉ™dÉ™r bÃ¶yÃ¼k olsa, model bir sÃ¶zÃ¼ bir tokenlÉ™ ifadÉ™ etmÉ™yÉ™ o qÉ™dÉ™r yaxÄ±n olar, lakin bu, modelin yaddaÅŸ tÉ™lÉ™bini artÄ±rar. 32,000 optimal bir balans tÉ™min edir.

## 10.5. GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Tokenizator KitabxanasÄ±nÄ±n QuraÅŸdÄ±rÄ±lmasÄ±

NÃ¶vbÉ™ti gÃ¼n BPE tokenizatorunu tÉ™lim etmÉ™k Ã¼Ã§Ã¼n Hugging Face-in **`tokenizers`** kitabxanasÄ±ndan istifadÉ™ edilÉ™cÉ™k. Bu kitabxana Rust dilindÉ™ yazÄ±ldÄ±ÄŸÄ± Ã¼Ã§Ã¼n Ã§ox sÃ¼rÉ™tlidir.

```bash
pip install tokenizers
```
