# GÃ¼n 10: Tokenizasiya I: SÃ¶zlÉ™ri RÉ™qÉ™mlÉ™rÉ™ Ã‡evirmÉ™k ğŸ”¢

## 10.1. NiyÉ™ Tokenizasiya?

Ä°ndiyÉ™ qÉ™dÉ™r biz tÉ™miz vÉ™ normallaÅŸdÄ±rÄ±lmÄ±ÅŸ mÉ™tn korpusu yaratdÄ±q. Lakin kompÃ¼terlÉ™r vÉ™ neyron ÅŸÉ™bÉ™kÉ™lÉ™r mÉ™tnlÉ™ deyil, **rÉ™qÉ™mlÉ™rlÉ™** iÅŸlÉ™yir. **Tokenizasiya** prosesi mÉ™tnimizi modelin baÅŸa dÃ¼ÅŸÉ™cÉ™yi rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±na Ã§evirmÉ™kdir.

**Token** â€“ mÉ™tnin É™n kiÃ§ik mÉ™nalÄ± vahididir. Bu, bir sÃ¶z, bir simvol vÉ™ ya bir sÃ¶zÃ¼n hissÉ™si ola bilÉ™r.

**Vocabulary (LÃ¼ÄŸÉ™t)** â€“ korpusumuzda rast gÉ™linÉ™n bÃ¼tÃ¼n unikal tokenlÉ™rin siyahÄ±sÄ±dÄ±r. HÉ™r bir tokenin bu lÃ¼ÄŸÉ™tdÉ™ Ã¶zÃ¼nÉ™mÉ™xsus bir **ID (Ä°dentifikator)** nÃ¶mrÉ™si var.

## 10.2. Byte Pair Encoding (BPE) NÉ™dir?

LLM-lÉ™rdÉ™ É™n Ã§ox istifadÉ™ olunan tokenizasiya Ã¼sulu **Byte Pair Encoding (BPE)**-dir.

**BPE-nin Æsas Prinsipi:**

1.  **BaÅŸlanÄŸÄ±c:** BÃ¼tÃ¼n mÉ™tn simvollara bÃ¶lÃ¼nÃ¼r (mÉ™sÉ™lÉ™n, "AzÉ™rbaycan" -> \['A', 'z', 'É™', 'r', 'b', 'a', 'y', 'c', 'a', 'n']).
2.  **TÉ™krarlama:** Æn Ã§ox tÉ™krarlanan ardÄ±cÄ±l simvol cÃ¼tlÉ™ri tapÄ±lÄ±r vÉ™ yeni bir token kimi lÃ¼ÄŸÉ™tÉ™ É™lavÉ™ olunur.
3.  **BirlÉ™ÅŸdirmÉ™:** Bu yeni tokenlÉ™r mÉ™tndÉ™ki cÃ¼tlÉ™ri É™vÉ™z edir.
4.  **Son:** Bu proses, ya lÃ¼ÄŸÉ™tin Ã¶lÃ§Ã¼sÃ¼ (mÉ™sÉ™lÉ™n, 32000 token) mÃ¼É™yyÉ™n bir hÉ™ddÉ™ Ã§atana qÉ™dÉ™r, ya da É™n Ã§ox tÉ™krarlanan cÃ¼tlÃ¼yÃ¼n sayÄ± Ã§ox az olana qÉ™dÉ™r davam edir.

**NiyÉ™ BPE?**

*   **SÃ¶zlÉ™ri Qoruyur:** Tez-tez rast gÉ™linÉ™n sÃ¶zlÉ™r bir token kimi qalÄ±r (mÉ™sÉ™lÉ™n, "AzÉ™rbaycan").
*   **Nadir SÃ¶zlÉ™ri HÉ™ll Edir:** Nadir vÉ™ ya yeni sÃ¶zlÉ™r (mÉ™sÉ™lÉ™n, "kvantlaÅŸdÄ±rma") hissÉ™lÉ™rÉ™ bÃ¶lÃ¼nÃ¼r (mÉ™sÉ™lÉ™n, \['kvant', 'laÅŸ', 'dÄ±r', 'ma']). Bu, modelin hÉ™r bir sÃ¶zÃ¼ gÃ¶rmÉ™sÉ™ belÉ™, onun hissÉ™lÉ™rini tanÄ±maÄŸa imkan verir.

## 10.3. AzÉ™rbaycan Dili Ã¼Ã§Ã¼n Tokenizasiya

AzÉ™rbaycan dili **aqqlÃ¼tinativ** (iltisaqi) bir dildir. YÉ™ni, sÃ¶zlÉ™rÉ™ Ã§oxlu sayda ÅŸÉ™kilÃ§ilÉ™r qoÅŸulur (mÉ™sÉ™lÉ™n, "kitablarÄ±mÄ±zdakÄ±lardan").

BPE bu cÃ¼r dillÉ™r Ã¼Ã§Ã¼n Ã§ox uyÄŸundur, Ã§Ã¼nki:

*   **KÃ¶k SÃ¶zlÉ™r:** "kitab" kimi kÃ¶k sÃ¶zlÉ™r tÉ™k token kimi qalÄ±r.
*   **ÅÉ™kilÃ§ilÉ™r:** "-larÄ±mÄ±z", "-dakÄ±", "-lardan" kimi ÅŸÉ™kilÃ§ilÉ™r ayrÄ±ca tokenlÉ™r kimi Ã¶yrÉ™nilir.

Bu, modelin kiÃ§ik bir lÃ¼ÄŸÉ™tlÉ™ belÉ™ sonsuz sayda sÃ¶z kombinasiyasÄ±nÄ± anlamaq qabiliyyÉ™tini artÄ±rÄ±r.

## 10.4. GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Tokenizatorun TÉ™liminÉ™ HazÄ±rlÄ±q

Sabah biz Python-un `tokenizers` kitabxanasÄ±ndan istifadÉ™ edÉ™rÉ™k BPE tokenizatorumuzu tÉ™lim edÉ™cÉ™yik. Bu gÃ¼nÃ¼n tapÅŸÄ±rÄ±ÄŸÄ± isÉ™ bu proses Ã¼Ã§Ã¼n lazÄ±m olan kitabxanalarÄ± quraÅŸdÄ±rmaqdÄ±r.

**Terminalda icra edin:**

```bash
# Tokenizatorun tÉ™limi Ã¼Ã§Ã¼n É™sas kitabxana
pip install tokenizers
```

**Qeyd:** Bizim LLM modelimiz Ã¼Ã§Ã¼n É™n optimal lÃ¼ÄŸÉ™t Ã¶lÃ§Ã¼sÃ¼ (Vocabulary Size) tÉ™xminÉ™n **32000** olacaq. Bu rÉ™qÉ™m, dilin zÉ™nginliyini qorumaq vÉ™ modelin yaddaÅŸ tÉ™lÉ™bini minimuma endirmÉ™k Ã¼Ã§Ã¼n yaxÅŸÄ± bir tarazlÄ±qdÄ±r.
