# GÃ¼n 31: PyTorch-dan Hugging Face-É™ Ã‡evirmÉ™ (I HissÉ™) ğŸ”„

## 31.1. NiyÉ™ Hugging Face?

Biz modelimizi PyTorch-da sÄ±fÄ±rdan qurduq. Bu, Ã¶yrÉ™nmÉ™k Ã¼Ã§Ã¼n É™la idi. Lakin sÉ™naye standartÄ± olan **Hugging Face (HF) Transformers** kitabxanasÄ± modelimizi paylaÅŸmaq, kvantlaÅŸdÄ±rmaq vÉ™ Ollama kimi platformalarda istifadÉ™ etmÉ™k Ã¼Ã§Ã¼n vacibdir.

**Hugging Face-in FaydalarÄ±:**

1.  **StandartlaÅŸdÄ±rma:** BÃ¼tÃ¼n LLM-lÉ™r Ã¼Ã§Ã¼n vahid bir interfeys tÉ™min edir.
2.  **Eko-sistem:** KvantlaÅŸdÄ±rma, tÉ™lim, proqnozlaÅŸdÄ±rma Ã¼Ã§Ã¼n minlÉ™rlÉ™ alÉ™t vÉ™ skript mÃ¶vcuddur.
3.  **PaylaÅŸÄ±m:** Modelinizi GitHub-da dostlarÄ±nÄ±zla paylaÅŸmaq Ã¼Ã§Ã¼n HF Hub É™n yaxÅŸÄ± platformadÄ±r.

Bizim mÉ™qsÉ™dimiz **`az_llm_100m_final.pt`** faylÄ±ndakÄ± Ã§É™kilÉ™ri HF-in tanÄ±dÄ±ÄŸÄ± formata Ã§evirmÉ™kdir.

## 31.2. Hugging Face Konfiqurasiya FaylÄ±

HF modelinin dÃ¼zgÃ¼n iÅŸlÉ™mÉ™si Ã¼Ã§Ã¼n **`config.json`** adlÄ± bir konfiqurasiya faylÄ±na ehtiyacÄ±mÄ±z var. Bu fayl modelin bÃ¼tÃ¼n hiperparametrlÉ™rini (n_embd, n_layer, n_head vÉ™ s.) saxlayÄ±r.

**`create_config.py`**

```python
import json
import os

# Modelin hiperparametrlÉ™ri (GÃ¼n 13-dÉ™n)
config = {
    "architectures": ["GPT2LMHeadModel"], # GPT2-yÉ™ bÉ™nzÉ™r arxitektura
    "model_type": "gpt2",
    "vocab_size": 32000,
    "n_embd": 768,
    "n_layer": 12,
    "n_head": 12,
    "n_positions": 256, # block_size
    "attn_pdrop": 0.1, # Dropout dÉ™rÉ™cÉ™si
    "embd_pdrop": 0.1,
    "resid_pdrop": 0.1,
    "initializer_range": 0.02,
    "bos_token_id": 50256, # BaÅŸlanÄŸÄ±c tokeni (GPT2 standartÄ±)
    "eos_token_id": 50256, # Son tokeni (GPT2 standartÄ±)
}

OUTPUT_DIR = "az_llm_hf"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Konfiqurasiya faylÄ±nÄ± yadda saxlamaq
config_path = os.path.join(OUTPUT_DIR, "config.json")
with open(config_path, 'w') as f:
    json.dump(config, f, indent=4)

print(f"Konfiqurasiya faylÄ± '{config_path}' yaradÄ±ldÄ±.")
```

## 31.3. Hugging Face Tokenizator FaylÄ±

HF modelinin dÃ¼zgÃ¼n iÅŸlÉ™mÉ™si Ã¼Ã§Ã¼n hÉ™mÃ§inin tokenizatorumuzu da HF formatÄ±na Ã§evirmÉ™liyik.

**`az_llm-tokenizer.json`** faylÄ±mÄ±z artÄ±q HF-in `tokenizers` kitabxanasÄ± tÉ™rÉ™findÉ™n yaradÄ±ldÄ±ÄŸÄ± Ã¼Ã§Ã¼n, bizÉ™ sadÉ™cÉ™ olaraq HF-in `PreTrainedTokenizerFast` sinfini istifadÉ™ edÉ™rÉ™k onu yÃ¼klÉ™mÉ™k vÉ™ lazÄ±mi fayllarÄ± (mÉ™sÉ™lÉ™n, `tokenizer.json`) saxlamaq lazÄ±mdÄ±r.

**`save_tokenizer.py`**

```python
from transformers import PreTrainedTokenizerFast
from tokenizers import Tokenizer
import os

TOKENIZER_FILE = "az_llm-tokenizer.json"
OUTPUT_DIR = "az_llm_hf"

# 1. Tokenizatoru yÃ¼klÉ™mÉ™k
tokenizer = Tokenizer.from_file(TOKENIZER_FILE)

# 2. Hugging Face formatÄ±na Ã§evirmÉ™k
hf_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    bos_token="<|endoftext|>", # BaÅŸlanÄŸÄ±c tokeni
    eos_token="<|endoftext|>", # Son tokeni
    unk_token="[UNK]",         # NamÉ™lum token
    pad_token="[PAD]",         # Doldurma tokeni
)

# 3. FayllarÄ± yadda saxlamaq
hf_tokenizer.save_pretrained(OUTPUT_DIR)

print(f"Hugging Face tokenizator fayllarÄ± '{OUTPUT_DIR}' qovluÄŸuna yazÄ±ldÄ±.")
```

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** `create_config.py` vÉ™ `save_tokenizer.py` skriptlÉ™rini yaradÄ±n vÉ™ iÅŸÉ™ salÄ±n. NÉ™ticÉ™dÉ™ `az_llm_hf` qovluÄŸunda `config.json` vÉ™ tokenizator fayllarÄ± yaranmalÄ±dÄ±r.
