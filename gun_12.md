# GÃ¼n 12: MÉ™lumatÄ±n HazÄ±rlanmasÄ±: RÉ™qÉ™mlÉ™ÅŸdirmÉ™ ğŸ’¾

## 12.1. MÉ™lumatÄ±n RÉ™qÉ™mlÉ™ÅŸdirilmÉ™si

ÆvvÉ™lki gÃ¼nlÉ™rdÉ™:
1.  **Korpusu topladÄ±q** (`normalized_corpus.txt`).
2.  **Tokenizatoru tÉ™lim etdik** (`az_llm-tokenizer.json`).

Ä°ndi isÉ™ son addÄ±m: **Korpusu Token ID-lÉ™rinÉ™ Ã§evirmÉ™k** vÉ™ modelin tÉ™limi Ã¼Ã§Ã¼n hazÄ±r vÉ™ziyyÉ™tÉ™ gÉ™tirmÉ™k.

Bizim LLM-imiz **Transformer** arxitekturasÄ±na É™saslanacaq vÉ™ bu model **ardÄ±cÄ±l mÉ™tnlÉ™ri** emal edir. Buna gÃ¶rÉ™ dÉ™, bÃ¼tÃ¼n korpusumuzu bÃ¶yÃ¼k bir rÉ™qÉ™mlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±na Ã§evirÉ™cÉ™yik.

## 12.2. Praktika: Token ID-lÉ™rinÉ™ Ã‡evirmÉ™

Biz bÃ¼tÃ¼n `normalized_corpus.txt` faylÄ±nÄ± oxuyacaq, hÉ™r bir sÉ™tri tokenizatorumuzla rÉ™qÉ™mlÉ™rÉ™ Ã§evirÉ™cÉ™k vÉ™ nÉ™ticÉ™ni **NumPy** massivi kimi yadda saxlayacaÄŸÄ±q. NumPy massivi bÃ¶yÃ¼k rÉ™qÉ™mlÉ™r toplusunu yaddaÅŸda daha effektiv saxlamaÄŸa imkan verir.

**`prepare_data.py`**

```python
import numpy as np
from tokenizers import Tokenizer
import os

# 1. GiriÅŸ vÉ™ Ã‡Ä±xÄ±ÅŸ FayllarÄ±
CORPUS_FILE = "normalized_corpus.txt"
TOKENIZER_FILE = "az_llm-tokenizer.json"
OUTPUT_DIR = "data"

def prepare_dataset():
    """Korpusu token ID-lÉ™rinÉ™ Ã§evirir vÉ™ NumPy massivi kimi saxlayÄ±r."""
    
    # 2. Tokenizatoru yÃ¼klÉ™mÉ™k
    try:
        tokenizer = Tokenizer.from_file(TOKENIZER_FILE)
    except Exception as e:
        print(f"XÉ™ta: Tokenizator faylÄ± '{TOKENIZER_FILE}' tapÄ±lmadÄ±. ZÉ™hmÉ™t olmasa, GÃ¼n 11-i tamamlayÄ±n.")
        return

    # 3. Korpusu oxumaq
    print(f"'{CORPUS_FILE}' faylÄ± oxunur...")
    with open(CORPUS_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # 4. BÃ¼tÃ¼n mÉ™tnlÉ™ri token ID-lÉ™rinÉ™ Ã§evirmÉ™k
    all_ids = []
    print("MÉ™tnlÉ™r token ID-lÉ™rinÉ™ Ã§evrilir...")
    
    # Batch Encoding istifadÉ™ edÉ™rÉ™k prosesi sÃ¼rÉ™tlÉ™ndiririk
    encodings = tokenizer.encode_batch(lines)
    
    for encoding in encodings:
        all_ids.extend(encoding.ids)

    # 5. NumPy massivinÉ™ Ã§evirmÉ™k
    # dtype='uint16' istifadÉ™ edirik, Ã§Ã¼nki 32000 lÃ¼ÄŸÉ™t Ã¶lÃ§Ã¼sÃ¼ Ã¼Ã§Ã¼n 16 bit kifayÉ™tdir
    # Bu, yaddaÅŸda yerÉ™ qÉ™naÉ™t edir.
    data = np.array(all_ids, dtype=np.uint16)
    
    print(f"Ãœmumi token sayÄ±: {len(data)}")
    print(f"NumPy massivinin Ã¶lÃ§Ã¼sÃ¼: {data.nbytes / (1024*1024):.2f} MB")

    # 6. TÉ™lim vÉ™ Validasiya DÉ™stlÉ™rinÉ™ BÃ¶lmÉ™k
    # 90% TÉ™lim (Train), 10% Validasiya (Validation)
    train_ratio = 0.9
    split_index = int(train_ratio * len(data))
    
    train_data = data[:split_index]
    val_data = data[split_index:]

    # 7. NÉ™ticÉ™lÉ™ri yadda saxlamaq
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    train_path = os.path.join(OUTPUT_DIR, 'train.bin')
    val_path = os.path.join(OUTPUT_DIR, 'val.bin')
    
    train_data.tofile(train_path)
    val_data.tofile(val_path)
    
    print(f"\n--- NÉ™ticÉ™ ---")
    print(f"TÉ™lim dÉ™sti ({len(train_data)} token) '{train_path}' faylÄ±na yazÄ±ldÄ±.")
    print(f"Validasiya dÉ™sti ({len(val_data)} token) '{val_path}' faylÄ±na yazÄ±ldÄ±.")

if __name__ == "__main__":
    prepare_dataset()
```

## 12.3. Kodun Ä°zahÄ±

| SÉ™tr | Kod | Ä°zahÄ± |
| :--- | :--- | :--- |
| **2** | `import numpy as np` | Riyazi É™mÉ™liyyatlar vÉ™ bÃ¶yÃ¼k massivlÉ™rlÉ™ iÅŸlÉ™mÉ™k Ã¼Ã§Ã¼n kitabxana. |
| **27** | `encodings = tokenizer.encode_batch(lines)` | BÃ¼tÃ¼n sÉ™tirlÉ™ri bir dÉ™fÉ™yÉ™ token ID-lÉ™rinÉ™ Ã§evirir. Bu, `for` dÃ¶vrÃ¼ndÉ™ tÉ™k-tÉ™k Ã§evirmÉ™kdÉ™n daha sÃ¼rÉ™tlidir. |
| **30** | `all_ids.extend(encoding.ids)` | HÉ™r bir sÉ™trin token ID-lÉ™rini Ã¼mumi siyahÄ±ya É™lavÉ™ edir. |
| **34** | `data = np.array(all_ids, dtype=np.uint16)` | BÃ¼tÃ¼n ID-lÉ™ri **16-bitlik tam É™dÉ™d** (unsigned integer) massivinÉ™ Ã§evirir. Bu, hÉ™r bir token ID-si Ã¼Ã§Ã¼n 2 bayt yaddaÅŸ istifadÉ™ etmÉ™yimiz demÉ™kdir. |
| **40** | `split_index = int(train_ratio * len(data))` | MÉ™lumatÄ± 90% tÉ™lim vÉ™ 10% validasiya olaraq bÃ¶lmÉ™k Ã¼Ã§Ã¼n sÉ™rhÉ™d nÃ¶qtÉ™sini hesablayÄ±r. |
| **47** | `train_data.tofile(train_path)` | TÉ™lim dÉ™stini ikili (binary) formatda yadda saxlayÄ±r. Bu, mÉ™lumatÄ± tez vÉ™ effektiv ÅŸÉ™kildÉ™ yÃ¼klÉ™mÉ™yÉ™ imkan verir. |

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** `prepare_data.py` skriptini yaradÄ±n vÉ™ iÅŸÉ™ salÄ±n. `data` qovluÄŸunun iÃ§indÉ™ `train.bin` vÉ™ `val.bin` fayllarÄ±nÄ±n yarandÄ±ÄŸÄ±nÄ± yoxlayÄ±n. **TÉ™brik edirik!** Siz artÄ±q LLM tÉ™limi Ã¼Ã§Ã¼n lazÄ±m olan bÃ¼tÃ¼n mÉ™lumat hazÄ±rlÄ±ÄŸÄ± mÉ™rhÉ™lÉ™sini sÄ±fÄ±rdan tamamladÄ±nÄ±z.
