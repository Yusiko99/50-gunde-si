# GÃ¼n 26: TÉ™limin Monitorinqi vÉ™ VizualizasiyasÄ± ğŸ“Š

## 26.1. Monitorinqin ÆhÉ™miyyÉ™ti

LLM tÉ™limi, xÃ¼susilÉ™ mÉ™hdud resurslarda, uzun vÉ™ resurs-tÉ™lÉ™bkar bir prosesdir. TÉ™limin gediÅŸatÄ±nÄ± **monitorinq etmÉ™k** modelin dÃ¼zgÃ¼n Ã¶yrÉ™ndiyini, Overfitting (hÉ™ddindÉ™n artÄ±q É™zbÉ™rlÉ™mÉ™) riskinin olub-olmadÄ±ÄŸÄ±nÄ± vÉ™ optimallaÅŸdÄ±rmanÄ±n effektivliyini yoxlamaq Ã¼Ã§Ã¼n zÉ™ruridir.

**Æsas Monitorinq MetrikalarÄ±:**

1.  **TÉ™lim Loss-u (Training Loss):** Modelin tÉ™lim mÉ™lumatlarÄ± Ã¼zÉ™rindÉ™ki sÉ™hvi.
2.  **Validasiya Loss-u (Validation Loss):** Modelin gÃ¶rmÉ™diyi mÉ™lumatlar Ã¼zÉ™rindÉ™ki sÉ™hvi.
3.  **Ã–yrÉ™nmÉ™ SÃ¼rÉ™ti (Learning Rate):** Optimizerin hÉ™r addÄ±mda Ã§É™kilÉ™ri nÉ™ qÉ™dÉ™r dÉ™yiÅŸdirdiyi.

## 26.2. Perplexity (PPL) MetrikasÄ±

Loss dÉ™yÉ™ri riyazi bir Ã¶lÃ§Ã¼ olsa da, **Perplexity (PPL)** modelin dil Ã¼zÉ™rindÉ™ki qabiliyyÉ™tini daha intuitiv ÅŸÉ™kildÉ™ ifadÉ™ edir.

*   **NÉ™dir?** PPL, Loss-un eksponensial funksiyasÄ±dÄ±r: $PPL = e^{Loss}$.
*   **MÉ™ntiq:** PPL modelin nÃ¶vbÉ™ti tokeni proqnozlaÅŸdÄ±rmaqda nÉ™ qÉ™dÉ™r "Ã§aÅŸqÄ±n" olduÄŸunu gÃ¶stÉ™rir. PPL dÉ™yÉ™ri nÉ™ qÉ™dÉ™r aÅŸaÄŸÄ± olarsa, modelin proqnozlaÅŸdÄ±rmasÄ± bir o qÉ™dÉ™r dÉ™qiqdir. MÉ™sÉ™lÉ™n, PPL=10 o demÉ™kdir ki, model hÉ™r nÃ¶vbÉ™ti token Ã¼Ã§Ã¼n orta hesabla 10 bÉ™rabÉ™r ehtimallÄ± seÃ§im arasÄ±nda qalÄ±r.

## 26.3. Vizualizasiya Ã¼Ã§Ã¼n `TensorBoard`

TÉ™lim metrikalarÄ±nÄ± vizual ÅŸÉ™kildÉ™ izlÉ™mÉ™k Ã¼Ã§Ã¼n **TensorBoard** É™n geniÅŸ yayÄ±lmÄ±ÅŸ alÉ™tdir.

**TensorBoard-un Ä°nteqrasiyasÄ±:**

1.  **QuraÅŸdÄ±rma:** `pip install tensorboard`
2.  **`SummaryWriter`:** PyTorch-da `torch.utils.tensorboard.SummaryWriter` istifadÉ™ edÉ™rÉ™k metrikalarÄ± log fayllarÄ±na yazmaq.

**`train_accelerate.py` SkriptinÉ™ ÆlavÉ™lÉ™r:**

```python
# ... (ÆvvÉ™lki kod) ...
from torch.utils.tensorboard import SummaryWriter

# 1. Konfiqurasiya
# ...
LOG_DIR = "runs/az_llm_experiment_1"
writer = SummaryWriter(LOG_DIR)
global_step = 0

# ... (TÉ™lim dÃ¶vrÃ¼) ...

for epoch in range(NUM_EPOCHS):
    model.train()
    for step, batch in enumerate(train_dataloader):
        # ... (TÉ™lim addÄ±mlarÄ±) ...
        
        # 7. MetrikalarÄ±n LoglanmasÄ±
        if step % 10 == 0:
            # TÉ™lim Loss-unu loglamaq
            writer.add_scalar('Loss/Train', loss.item(), global_step)
            
            # Ã–yrÉ™nmÉ™ SÃ¼rÉ™tini loglamaq
            current_lr = optimizer.param_groups[0]['lr']
            writer.add_scalar('Learning_Rate', current_lr, global_step)
            
        global_step += 1
        
    # HÉ™r epoxanÄ±n sonunda Validasiya Loss-unu loglamaq
    # ... (GÃ¼n 27-dÉ™ É™lavÉ™ olunacaq) ...

# TÉ™lim bitdikdÉ™n sonra
writer.close()
```

## 26.4. TensorBoard-un Ä°ÅŸÉ™ SalÄ±nmasÄ±

TÉ™lim skripti iÅŸlÉ™yÉ™rkÉ™n, baÅŸqa bir terminalda TensorBoard-u iÅŸÉ™ salmaq lazÄ±mdÄ±r:

```bash
tensorboard --logdir=runs
```

Bu É™mr, yerli kompÃ¼terdÉ™ bir veb-server iÅŸÉ™ salacaq (adÉ™tÉ™n `http://localhost:6006`). Bu Ã¼nvana daxil olaraq tÉ™limin gediÅŸatÄ±nÄ± qrafiklÉ™r ÅŸÉ™klindÉ™ izlÉ™mÉ™k mÃ¼mkÃ¼ndÃ¼r.

**MÉ™ntiq:** Vizualizasiya, tÉ™limin gediÅŸatÄ±nÄ± bir baxÄ±ÅŸda anlamaÄŸa vÉ™ Overfitting kimi problemlÉ™ri erkÉ™n aÅŸkar etmÉ™yÉ™ imkan verir.
