# GÃ¼n 26: TÉ™limin Monitorinqi ğŸ“Š

## 26.1. NiyÉ™ Monitorinq Vacibdir?

Modelin tÉ™limi uzun vÉ™ resurs tÉ™lÉ™b edÉ™n bir prosesdir. TÉ™limin gediÅŸatÄ±nÄ± izlÉ™mÉ™k (monitorinq) aÅŸaÄŸÄ±dakÄ±lar Ã¼Ã§Ã¼n vacibdir:

1.  **ErkÉ™n XÉ™bÉ™rdarlÄ±q:** Modelin Ã¶yrÉ™nmÉ™diyini (Loss-un azalmamasÄ±) vÉ™ ya hÉ™ddindÉ™n artÄ±q Ã¶yrÉ™ndiyini (Overfitting) erkÉ™n aÅŸkar etmÉ™k.
2.  **Resurs Ä°darÉ™etmÉ™si:** GPU-nun VRAM istifadÉ™sini vÉ™ temperaturunu izlÉ™mÉ™k.
3.  **QÉ™rar QÉ™bulu:** TÉ™limi nÉ™ vaxt dayandÄ±rmaq lazÄ±m olduÄŸunu mÃ¼É™yyÉ™nlÉ™ÅŸdirmÉ™k.

Biz tÉ™limi izlÉ™mÉ™k Ã¼Ã§Ã¼n **Loss (Ä°tki)** vÉ™ **Perplexity (PPL)** metrikalarÄ±ndan istifadÉ™ edÉ™cÉ™yik.

## 26.2. Æsas Metrikalar

### A. Loss (Ä°tki)

**Loss** modelin proqnozlarÄ± ilÉ™ hÉ™qiqi nÉ™ticÉ™lÉ™r arasÄ±ndakÄ± fÉ™rqi gÃ¶stÉ™rÉ™n rÉ™qÉ™mdir.

*   **TÉ™lim Loss-u (Training Loss):** Modelin tÉ™lim mÉ™lumatlarÄ± Ã¼zÉ™rindÉ™ nÉ™ qÉ™dÉ™r yaxÅŸÄ± iÅŸlÉ™diyini gÃ¶stÉ™rir.
*   **Validasiya Loss-u (Validation Loss):** Modelin **gÃ¶rmÉ™diyi** mÉ™lumatlar Ã¼zÉ™rindÉ™ nÉ™ qÉ™dÉ™r yaxÅŸÄ± Ã¼mumilÉ™ÅŸdirdiyini gÃ¶stÉ™rir.

**Ä°deal Senari:** HÉ™m TÉ™lim, hÉ™m dÉ™ Validasiya Loss-u zamanla azalmalÄ±dÄ±r.

### B. Perplexity (PPL)

**Perplexity** (Ã‡É™tinlik/Qeyri-mÃ¼É™yyÉ™nlik) dil modellÉ™rinin keyfiyyÉ™tini Ã¶lÃ§mÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunan daha intuitiv bir metrikadÄ±r.

*   **Ä°zahÄ±:** Modelin nÃ¶vbÉ™ti tokeni proqnozlaÅŸdÄ±rmaqda nÉ™ qÉ™dÉ™r "Ã§aÅŸqÄ±n" olduÄŸunu gÃ¶stÉ™rir.
*   **DÉ™yÉ™r:** Loss-un eksponensialÄ± kimi hesablanÄ±r: $PPL = e^{\text{Loss}}$.
*   **Ä°deal Senari:** PPL dÉ™yÉ™ri nÉ™ qÉ™dÉ™r kiÃ§ik olsa, model o qÉ™dÉ™r yaxÅŸÄ±dÄ±r. MÉ™sÉ™lÉ™n, PPL=10 o demÉ™kdir ki, model hÉ™r nÃ¶vbÉ™ti token Ã¼Ã§Ã¼n 10 bÉ™rabÉ™r ehtimal olunan seÃ§im arasÄ±nda qÉ™rar verir.

## 26.3. Praktika: Monitorinqin TÉ™tbiqi

Biz monitorinq Ã¼Ã§Ã¼n **TensorBoard** vÉ™ ya **Weights & Biases (W&B)** kimi alÉ™tlÉ™rdÉ™n istifadÉ™ edÉ™ bilÉ™rik. SadÉ™lik Ã¼Ã§Ã¼n, biz nÉ™ticÉ™lÉ™ri hÉ™r addÄ±mda terminala Ã§ap edÉ™cÉ™yik vÉ™ modelin keyfiyyÉ™tini É™l ilÉ™ izlÉ™yÉ™cÉ™yik.

**`train_accelerate.py` skriptindÉ™ dÉ™yiÅŸikliklÉ™r:**

```python
# ... (ÆvvÉ™lki kodlar) ...

# TÉ™lim dÃ¶vrÃ¼
for step, batch in enumerate(train_dataloader):
    # ... (Forward pass vÉ™ loss hesablanmasÄ±) ...
    
    # Loss-u geri yaymaq (Backpropagation)
    accelerator.backward(loss)
    
    # QradiyentlÉ™ri yenilÉ™mÉ™k
    optimizer.step()
    optimizer.zero_grad()
    
    # ------------------------------------------------
    # 1. Monitorinq: HÉ™r 100 addÄ±mda nÉ™ticÉ™ni Ã§ap etmÉ™k
    if step % 100 == 0:
        # Loss-u CPU-ya kÃ¶Ã§Ã¼rÃ¼b rÉ™qÉ™mÉ™ Ã§evirmÉ™k
        current_loss = loss.item()
        # Perplexity hesablamaq
        perplexity = torch.exp(torch.tensor(current_loss))
        
        # Terminala Ã§ap etmÉ™k
        print(f"Epoch {epoch} | Step {step}/{len(train_dataloader)} | Loss: {current_loss:.4f} | PPL: {perplexity:.2f}")
        
        # 2. Validasiya Loss-unun HesablanmasÄ± (HÉ™r 1000 addÄ±mda)
        if step % 1000 == 0 and step > 0:
            val_loss = estimate_loss(model, val_dataloader, accelerator)
            val_ppl = torch.exp(torch.tensor(val_loss))
            print(f"--- Validasiya NÉ™ticÉ™si ---")
            print(f"Validasiya Loss: {val_loss:.4f} | Validasiya PPL: {val_ppl:.2f}")
            print(f"---------------------------")
            
# ... (estimate_loss funksiyasÄ±) ...
@torch.no_grad() # Bu funksiyada qradiyentlÉ™ri hesablamaÄŸa ehtiyac yoxdur
def estimate_loss(model, dataloader, accelerator):
    model.eval() # Modeli qiymÉ™tlÉ™ndirmÉ™ rejiminÉ™ keÃ§irmÉ™k
    losses = []
    for batch in dataloader:
        # ... (Forward pass vÉ™ loss hesablanmasÄ±) ...
        # Loss-u CPU-ya kÃ¶Ã§Ã¼rÃ¼b siyahÄ±ya É™lavÉ™ etmÉ™k
        losses.append(accelerator.gather(loss).mean().item())
    model.train() # Modeli tÉ™lim rejiminÉ™ qaytarmaq
    return np.mean(losses)
```

## 26.4. Overfitting (HÉ™ddindÉ™n ArtÄ±q Ã–yrÉ™nmÉ™)

Monitorinq zamanÄ± É™n Ã§ox diqqÉ™t etmÉ™li olduÄŸunuz mÉ™qam **Overfitting**-dir:

> **Overfitting:** TÉ™lim Loss-u azalÄ±r, lakin Validasiya Loss-u artmaÄŸa baÅŸlayÄ±r.

Bu o demÉ™kdir ki, model tÉ™lim mÉ™lumatlarÄ±nÄ± É™zbÉ™rlÉ™yir, lakin yeni mÉ™lumatlar Ã¼zÉ™rindÉ™ Ã¼mumilÉ™ÅŸdirmÉ™ qabiliyyÉ™tini itirir. Overfitting baÅŸ verdikdÉ™, tÉ™limi dayandÄ±rmaq vÉ™ ya **Dropout** kimi tÉ™nzimlÉ™mÉ™ (Regularization) texnikalarÄ±nÄ± artÄ±rmaq lazÄ±mdÄ±r.

**GÃ¼ndÉ™lik TapÅŸÄ±rÄ±q:** `train_accelerate.py` skriptinÉ™ `estimate_loss` funksiyasÄ±nÄ± vÉ™ monitorinq kodlarÄ±nÄ± É™lavÉ™ edin. TÉ™limi baÅŸlatdÄ±qdan sonra, terminalda Loss vÉ™ PPL dÉ™yÉ™rlÉ™rinin necÉ™ dÉ™yiÅŸdiyini izlÉ™yin.
