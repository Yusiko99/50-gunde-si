# ğŸ“š 50 GÃ¼ndÉ™ SÃ¼ni-Ä°ntellekt: GÃ¼n 22

## VerilÉ™nlÉ™r YÃ¼klÉ™yicisi (DataLoader): MÉ™lumatÄ±n TÉ™chizatÄ± ğŸšš

Salam! DÃ¼nÉ™n tÉ™lim prosesinin É™sas komponentlÉ™ri (Loss, Optimizer) ilÉ™ tanÄ±ÅŸ olduq vÉ™ `train.py` skriptimizin tÉ™mÉ™lini qoyduq. Bu gÃ¼n isÉ™ modelimizi mÉ™lumatla tÉ™chiz edÉ™cÉ™k É™sas alÉ™ti â€“ **VerilÉ™nlÉ™r YÃ¼klÉ™yicisini (DataLoader)** quracaÄŸÄ±q.

### 1. NiyÉ™ DataLoader?

Bizim `train.npy` faylÄ±mÄ±zda **milyonlarla** token var. Model bu tokenlÉ™rin hamÄ±sÄ±nÄ± eyni anda emal edÉ™ bilmÉ™z.

> **DataLoader** â€” bÃ¶yÃ¼k mÉ™lumat bazasÄ±nÄ± kiÃ§ik, idarÉ™olunan hissÉ™lÉ™rÉ™ â€“ **Batch**-lÉ™rÉ™ bÃ¶lÃ¼r vÉ™ tÉ™lim prosesi Ã¼Ã§Ã¼n onlarÄ± ardÄ±cÄ±l olaraq GPU-ya Ã¶tÃ¼rÃ¼r.

DataLoader-in É™sas funksiyalarÄ±:
1.  **Batching:** MÉ™lumatÄ± `BATCH_SIZE` (mÉ™sÉ™lÉ™n, 12) Ã¶lÃ§Ã¼sÃ¼ndÉ™ hissÉ™lÉ™rÉ™ bÃ¶lÃ¼r.
2.  **Shuffling:** HÉ™r epoch-da (dÃ¶vrdÉ™) mÉ™lumatÄ± qarÄ±ÅŸdÄ±rÄ±r ki, model mÉ™lumatÄ±n sÄ±rasÄ±nÄ± É™zbÉ™rlÉ™mÉ™sin.
3.  **Parallel YÃ¼klÉ™mÉ™:** MÉ™lumatÄ± CPU-dan GPU-ya paralel ÅŸÉ™kildÉ™ yÃ¼klÉ™yir.

### 2. Dataset Sinfinin QurulmasÄ±

PyTorch-da DataLoader-i istifadÉ™ etmÉ™k Ã¼Ã§Ã¼n É™vvÉ™lcÉ™ **Dataset** adlÄ± bir sinif yaratmalÄ±yÄ±q. Bu sinif PyTorch-a mÉ™lumatÄ±n harada olduÄŸunu vÉ™ hÉ™r bir elementin necÉ™ alÄ±nacaÄŸÄ±nÄ± bildirir.

AÅŸaÄŸÄ±dakÄ± kodu **`data_loader.py`** adlÄ± bir faylda yazaq.

```python
# data_loader.py
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader

# 1. GPTDataset Sinfi
class GPTDataset(Dataset):
    """ TÉ™lim vÉ™ Validasiya mÉ™lumatlarÄ±nÄ± idarÉ™ edÉ™n PyTorch Dataset sinfi """

    def __init__(self, split, block_size):
        # split: 'train' vÉ™ ya 'val'
        # block_size: Modelin kontekst pÉ™ncÉ™rÉ™sinin uzunluÄŸu (512)
        self.block_size = block_size

        # MÉ™lumatÄ± .npy faylÄ±ndan yÃ¼klÉ™yirik
        file_path = f'{split}.npy'
        print(f"MÉ™lumat yÃ¼klÉ™nir: {file_path}")
        self.data = np.load(file_path).astype(np.uint16)
        print(f"YÃ¼klÉ™ndi. Ãœmumi token sayÄ±: {len(self.data):,}")

    def __len__(self):
        """ Dataset-dÉ™ki mÃ¼mkÃ¼n nÃ¼munÉ™lÉ™rin Ã¼mumi sayÄ±nÄ± qaytarÄ±r """
        # MÉ™lumatÄ±n uzunluÄŸu - block_size (Ã§Ã¼nki son block_size qÉ™dÉ™r nÃ¼munÉ™ yarada bilmÉ™rik)
        return len(self.data) - self.block_size

    def __getitem__(self, idx):
        """ VerilmiÅŸ indeks Ã¼Ã§Ã¼n bir nÃ¼munÉ™ (Batch) qaytarÄ±r """
        # idx: BaÅŸlanÄŸÄ±c indeks
        # T: ArdÄ±cÄ±llÄ±q uzunluÄŸu (block_size)
        T = self.block_size
        
        # 1. GiriÅŸ (Input)
        # idx-dÉ™n idx+T-yÉ™ qÉ™dÉ™r olan tokenlÉ™r
        x = self.data[idx:idx+T]
        
        # 2. HÉ™dÉ™f (Target)
        # idx+1-dÉ™n idx+T+1-É™ qÉ™dÉ™r olan tokenlÉ™r (bir addÄ±m irÉ™li sÃ¼rÃ¼ÅŸdÃ¼rÃ¼lmÃ¼ÅŸ)
        y = self.data[idx+1:idx+T+1]

        # NumPy massivlÉ™rini PyTorch Tensor-larÄ±na Ã§eviririk
        x = torch.from_numpy(x.astype(np.int64))
        y = torch.from_numpy(y.astype(np.int64))
        
        return x, y

# 2. get_dataloaders FunksiyasÄ±
def get_dataloaders(block_size, batch_size):
    """ TÉ™lim vÉ™ Validasiya Ã¼Ã§Ã¼n DataLoader-lÉ™ri yaradÄ±r """
    
    # Dataset-lÉ™ri yaradÄ±rÄ±q
    train_dataset = GPTDataset('train', block_size)
    val_dataset = GPTDataset('val', block_size)

    # DataLoader-lÉ™ri yaradÄ±rÄ±q
    train_loader = DataLoader(
        train_dataset,
        sampler=None,
        shuffle=True, # TÉ™lim mÉ™lumatÄ±nÄ± qarÄ±ÅŸdÄ±rÄ±rÄ±q
        batch_size=batch_size,
        num_workers=0, # MÉ™lumatÄ± yÃ¼klÉ™mÉ™k Ã¼Ã§Ã¼n istifadÉ™ olunan CPU nÃ¼vÉ™lÉ™rinin sayÄ±
        pin_memory=True, # GPU-ya sÃ¼rÉ™tli Ã¶tÃ¼rmÉ™ Ã¼Ã§Ã¼n
    )

    val_loader = DataLoader(
        val_dataset,
        sampler=None,
        shuffle=False, # Validasiya mÉ™lumatÄ±nÄ± qarÄ±ÅŸdÄ±rmaÄŸa ehtiyac yoxdur
        batch_size=batch_size,
        num_workers=0,
        pin_memory=True,
    )
    
    return train_loader, val_loader
```

### 3. Kodun Ä°zahÄ± (HÉ™r SÉ™trin DetallÄ± Ä°zahÄ±)

| SÉ™tr | Kod | Ä°zah |
| :--- | :--- | :--- |
| 10 | `class GPTDataset(Dataset):` | BÃ¼tÃ¼n PyTorch Dataset-lÉ™ri bu sinifdÉ™n miras almalÄ±dÄ±r. |
| 17 | `self.data = np.load(file_path).astype(np.uint16)` | ÆvvÉ™lki gÃ¼n yaratdÄ±ÄŸÄ±mÄ±z `train.npy` vÉ™ ya `val.npy` faylÄ±nÄ± yÃ¼klÉ™yirik. |
| 23 | `def __len__(self):` | Dataset-dÉ™ neÃ§É™ nÃ¼munÉ™ olduÄŸunu PyTorch-a bildirir. |
| 28 | `def __getitem__(self, idx):` | **Æsas funksiya.** PyTorch bu funksiyanÄ± Ã§aÄŸÄ±raraq mÉ™lumatÄ± alÄ±r. |
| 34 | `x = self.data[idx:idx+T]` | **GiriÅŸ (Input):** `idx` mÃ¶vqeyindÉ™n baÅŸlayaraq `T` (512) uzunluÄŸunda tokenlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±nÄ± seÃ§irik. |
| 38 | `y = self.data[idx+1:idx+T+1]` | **HÉ™dÉ™f (Target):** Bu, giriÅŸdÉ™n **bir addÄ±m irÉ™li sÃ¼rÃ¼ÅŸdÃ¼rÃ¼lmÃ¼ÅŸ** tokenlÉ™r ardÄ±cÄ±llÄ±ÄŸÄ±dÄ±r. |
| | | **NiyÉ™ sÃ¼rÃ¼ÅŸdÃ¼rÃ¼lmÃ¼ÅŸ?** Ã‡Ã¼nki model `x[i]` tokenini gÃ¶rÃ¼b `y[i]` tokenini proqnozlaÅŸdÄ±rmalÄ±dÄ±r. MÉ™sÉ™lÉ™n, `x[0]`-Ä± gÃ¶rÃ¼b `y[0]`-Ä± (yÉ™ni `x[1]`-i) proqnozlaÅŸdÄ±rÄ±r. |
| 41 | `x = torch.from_numpy(x.astype(np.int64))` | NumPy massivini PyTorch-un `Tensor` formatÄ±na Ã§eviririk. |
| 50 | `train_loader = DataLoader(...)` | **DataLoader** obyektini yaradÄ±rÄ±q. `shuffle=True` tÉ™lim mÉ™lumatÄ±nÄ± qarÄ±ÅŸdÄ±rÄ±r. |

### 4. TÉ™lim Skriptinin YenilÉ™nmÉ™si

Ä°ndi `train.py` skriptimizdÉ™ `get_dataloaders` funksiyasÄ±nÄ± istifadÉ™ edÉ™ bilÉ™rik.

```python
# train.py (YenilÉ™nmiÅŸ)
# ... (É™vvÉ™lki importlar) ...
from data_loader import get_dataloaders # Yeni import

# ... (É™vvÉ™lki hiperparametrlÉ™r) ...

# 5. DataLoader-lÉ™ri Yaratmaq
train_loader, val_loader = get_dataloaders(BLOCK_SIZE, BATCH_SIZE)

# ... (Model vÉ™ Optimizer-in yaradÄ±lmasÄ±) ...

# 6. TÉ™lim DÃ¶vrÃ¼ (Ä°ndi iÅŸlÉ™yÉ™cÉ™k!)
# for iter in tqdm(range(MAX_ITERS), desc="TÉ™lim"):
#     # MÉ™lumatÄ± yÃ¼klÉ™
#     x, y = next(iter(train_loader))
#     x, y = x.to(device), y.to(device)
#     # ... (qalan tÉ™lim addÄ±mlarÄ±) ...
```

### ğŸ’¡ GÃ¼nÃ¼n TapÅŸÄ±rÄ±ÄŸÄ±: Praktika

1.  **`data_loader.py`** faylÄ±nÄ± yaradÄ±n vÉ™ yuxarÄ±dakÄ± kodu ora kopyalayÄ±n.
2.  `train.npy` vÉ™ `val.npy` fayllarÄ±nÄ±n mÃ¶vcud olduÄŸundan É™min olun.
3.  KiÃ§ik bir sÄ±naq skripti yazÄ±n:
    ```python
    from data_loader import get_dataloaders
    train_loader, _ = get_dataloaders(block_size=512, batch_size=4)
    
    # Ä°lk Batch-i yÃ¼klÉ™
    x, y = next(iter(train_loader))
    print(f"GiriÅŸ (x) Ã¶lÃ§Ã¼sÃ¼: {x.shape}") # (4, 512) olmalÄ±dÄ±r
    print(f"HÉ™dÉ™f (y) Ã¶lÃ§Ã¼sÃ¼: {y.shape}") # (4, 512) olmalÄ±dÄ±r
    ```

**Sabah gÃ¶rÃ¼ÅŸÉ™nÉ™dÉ™k!** ğŸ‘‹ Sabah **TÉ™lim DÃ¶vrÃ¼nÃ¼n** bÃ¼tÃ¼n addÄ±mlarÄ±nÄ± (irÉ™li Ã¶tÃ¼rmÉ™, geriyÉ™ Ã¶tÃ¼rmÉ™, yenilÉ™nmÉ™) PyTorch-da birlÉ™ÅŸdirÉ™cÉ™yik.

***

**SÃ¶z SayÄ±:** 800 sÃ¶z.
